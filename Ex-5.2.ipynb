{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Data Analysis\n",
    "## Excercise 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input features import and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (145, 145, 200)\n",
      "Final shape:  (21025, 200)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(os.path.join(\"data\", \"partB\", \"indianpinearray.npy\"))\n",
    "print(\"Initial shape: \", X.shape)\n",
    "X = X.reshape(-1,200)\n",
    "print(\"Final shape: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth import and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (145, 145)\n",
      "Final shape:  (21025,)\n",
      "Classes:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n"
     ]
    }
   ],
   "source": [
    "y = np.load(os.path.join(\"data\", \"partB\", \"IPgt.npy\"))\n",
    "print(\"Initial shape: \", y.shape)\n",
    "y = y.reshape(-1)\n",
    "print(\"Final shape: \", y.shape)\n",
    "print(\"Classes: \", np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also class 0 in the dataset. I remove class 0 which corresponds to unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shapes:  (10249, 200) (10249,)\n",
      "Classes:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Frequencies:  [46, 1428, 830, 237, 483, 730, 28, 478, 20, 972, 2455, 593, 205, 1265, 386, 93]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'C:\\\\Users\\\\spele\\\\Miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[y!=0]\n",
    "y = y[y!=0]\n",
    "print(\"Final shapes: \", X.shape, y.shape)\n",
    "print(\"Classes: \", np.unique(y))\n",
    "def hist(y):\n",
    "    freq = [list(y).count(i) for i in np.unique(y)]\n",
    "    print(\"Frequencies: \", freq)\n",
    "    plt.bar(np.unique(y), height=freq)\n",
    "    plt.xticks(np.unique(y))\n",
    "    plt.show()\n",
    "    return plt\n",
    "hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ Validation/ Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape      :  (7174, 200)\n",
      "Training labels shape   :  (7174,)\n",
      "Test set shape          :  (3075, 200)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=69, stratify=y)\n",
    "print('Training set shape      : ', X_train.shape)\n",
    "print('Training labels shape   : ', y_train.shape)\n",
    "print('Test set shape          : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I normalise X inside [0,1]. I need to apply separate normalisation to the training and test sets in order for the training process to be fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46617916 0.40563682 0.15374732 ... 0.2244898  0.37096774 0.46938776]\n",
      " [0.1182206  0.44987513 0.12376874 ... 0.16326531 0.30645161 0.40816327]\n",
      " [0.35892748 0.40242597 0.11563169 ... 0.21428571 0.29032258 0.3877551 ]\n",
      " ...\n",
      " [0.69530774 0.63432037 0.39743041 ... 0.70408163 0.83870968 0.7755102 ]\n",
      " [0.11395491 0.40456654 0.15802998 ... 0.14285714 0.37096774 0.59183673]\n",
      " [0.09506399 0.31145202 0.15460385 ... 0.25510204 0.51612903 0.28571429]]\n",
      "[14  6 14  3 14 14  2  3  3  3  2 11 14 10  4  8 11 14  8 12 11 14 11 14\n",
      " 11 11 14 15  1  2  6 14]\n"
     ]
    }
   ],
   "source": [
    "sc = preprocessing.MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "print(X_train[:32])\n",
    "print(y_train[:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we train the classifiers using the GridSearch algorithm so as to decide the best hyperparameter values based on accuracy. We try different hyperparameter values for both kernel SVM and RandomForest algorithms. I also split in training/ test set, equally balancing all classes and I use less samples for tuning given that especially the RF algorithm is really resource consuming. We also use stratified K-Fold in GridSearch so as to be sure that cross validation is performed with balanced splits using StratifiedKFold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyper-parameters, based on accuracy for: SVM\n",
      "with parameter choice:\n",
      "{'kernel': ['rbf', 'linear'], 'gamma': ['scale', 'auto'], 'C': [10, 100, 1000]}\n",
      "\n",
      "Mean performance of each parameter combination based on Cross Validation\n",
      "       C  gamma  kernel     Score\n",
      "0     10  scale     rbf  0.859909\n",
      "1     10  scale  linear  0.856982\n",
      "2     10   auto     rbf  0.605520\n",
      "3     10   auto  linear  0.856982\n",
      "4    100  scale     rbf  0.897266\n",
      "5    100  scale  linear  0.849176\n",
      "6    100   auto     rbf  0.818789\n",
      "7    100   auto  linear  0.849176\n",
      "8   1000  scale     rbf  0.895176\n",
      "9   1000  scale  linear  0.833425\n",
      "10  1000   auto     rbf  0.872037\n",
      "11  1000   auto  linear  0.833425\n",
      "Best parameters combination:\n",
      "{'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "The scores are computed on the full evaluation set for the best combination of parameters\n",
      "Test score: 0.9203252032520325\n",
      "============================\n",
      "\n",
      "Tuning hyper-parameters, based on accuracy for: RandomForest\n",
      "with parameter choice:\n",
      "{'n_estimators': [200, 600], 'max_depth': [4, 10, None], 'min_samples_leaf': [1, 2, 5]}\n",
      "\n",
      "Mean performance of each parameter combination based on Cross Validation\n",
      "    max_depth  min_samples_leaf  n_estimators     Score\n",
      "0         4.0                 1           200  0.563702\n",
      "1         4.0                 1           600  0.563702\n",
      "2         4.0                 2           200  0.564678\n",
      "3         4.0                 2           600  0.563981\n",
      "4         4.0                 5           200  0.563005\n",
      "5         4.0                 5           600  0.564677\n",
      "6        10.0                 1           200  0.804012\n",
      "7        10.0                 1           600  0.804290\n",
      "8        10.0                 2           200  0.801364\n",
      "9        10.0                 2           600  0.800666\n",
      "10       10.0                 5           200  0.796345\n",
      "11       10.0                 5           600  0.794812\n",
      "12        NaN                 1           200  0.846388\n",
      "13        NaN                 1           600  0.848897\n",
      "14        NaN                 2           200  0.839557\n",
      "15        NaN                 2           600  0.839975\n",
      "16        NaN                 5           200  0.827012\n",
      "17        NaN                 5           600  0.827012\n",
      "Best parameters combination:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 600}\n",
      "\n",
      "The scores are computed on the full evaluation set for the best combination of parameters\n",
      "Test score: 0.8728455284552845\n",
      "============================\n",
      "\n",
      "{'SVM': 0.9203252032520325, 'RandomForest': 0.8728455284552845}\n"
     ]
    }
   ],
   "source": [
    "#Set the parameters of each model by cross-validation gridsearch\n",
    "names = [\"SVM\", \"RandomForest\"]\n",
    "algorithms = [SVC(), RandomForestClassifier(n_jobs=-1)]\n",
    "tuned_parameters = [{'kernel': ['rbf', 'linear'], 'gamma': ['scale', 'auto'], 'C': [10, 100, 1000]},\n",
    "                    {'n_estimators': [200, 600], 'max_depth': [4, 10, None], 'min_samples_leaf': [1, 2, 5]}]\n",
    "\n",
    "cv_scores = []\n",
    "best_scores = []\n",
    "params = []\n",
    "kfolds = StratifiedKFold(3)\n",
    "# Gridsearch loop for all classifiers\n",
    "i=0\n",
    "for (a, t_p) in list(zip(algorithms, tuned_parameters)):\n",
    "    print(\"Tuning hyper-parameters, based on accuracy for: {}\\nwith parameter choice:\\n{}\\n\".format(names[i], t_p))\n",
    "    clf = GridSearchCV(a, t_p, cv=kfolds.split(X_train, y_train), scoring = 'accuracy', n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Mean performance of each parameter combination based on Cross Validation\")\n",
    "    performance = pd.DataFrame(clf.cv_results_['params'])\n",
    "    performance[\"Score\"] = clf.cv_results_['mean_test_score']\n",
    "    print(performance)\n",
    "    print(\"Best parameters combination:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\nThe scores are computed on the full evaluation set for the best combination of parameters\")\n",
    "    #evaluate and store scores of estimators of each category on test set\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Test score:\", score)\n",
    "    print(\"============================\\n\")\n",
    "    #store round scores\n",
    "    cv_scores.append(clf.cv_results_[\"mean_test_score\"])\n",
    "    params.append(clf.best_params_)\n",
    "    best_scores.append(score)\n",
    "    i+=1\n",
    "final_scores = dict(zip(names, best_scores))\n",
    "print(\"Test set performances:\")\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import Dataset\n",
    "#from training import trainNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset function to be used by the dataloader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implement a dataset function that its main purpose is to feed the models with batches of data. In larger datasets this function can be used to read data straight from the disk by providing list of indices  to the feats and labels variables instead of the actual features and performing the access to the disk inside the _ _ getitem _ _ method. This is more kind of a simulation of this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndianPineArray(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = np.array(y).astype('int64')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #features = np.load(\"indianpinearray\")\n",
    "        return {'bands': self.X[index], 'labels': self.y[index]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ Test split & Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split again but this time I also use a valitation set because this time I am not going to use GridSearchCV that splits automatically the training set in smaller training and validation sets and applies Cross Validation Such a process proves to be extremely resource consuming for a neural network. For that reason we limit out study to one specific train and validation split. As far as the test set is concerned we don't use it at all during the training process in order to decide the hyperparameter values (learning rate, NN architecture, number of epochs to apply early stopping and stop training). We only use it for evaluation purposes at the end, as if it was generated after the training process which is like simulating a real world problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape      :  (7174, 200)\n",
      "Training labels shape   :  (7174,)\n",
      "Validation set shape    :  (3075, 200)\n",
      "Validation labels shape :  (3075,)\n",
      "Frequencies:  [32, 1000, 581, 166, 338, 511, 20, 335, 14, 680, 1718, 415, 144, 885, 270, 65]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAD4CAYAAAA5DjhhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWU0lEQVR4nO3df7Bc5X3f8fenwhBD7CKbiyNLIsKMcIMZLLBKaF0z2CS2AA+YtG7FpDZ13Mj2QGM3aWsIM8Fxhhkam1B7muKRjQIkNoQEE1QbGxTamHYmGAQWIH4FgWW4SJXk0NpuyZAA3/6x5yZr6erXvfc5e6/0fs3s7Nlnn7PfZ3WvVh+d5zlnU1VIkiSpnb836gFIkiQd6AxckiRJjRm4JEmSGjNwSZIkNWbgkiRJauyQUQ9gb4466qhasmTJqIchSZK0V/fff//3q2ps5/ZZH7iWLFnC+vXrRz0MSZKkvUryvcnanVKUJElqzMAlSZLU2F4DV5I1SbYn2TjU9odJNnS3zUk2dO1LkvzV0HNfGNrnbUkeTrIpyeeTpM1bkiRJml32ZQ3XdcB/Bm6YaKiqfzGxneQq4AdD/Z+qqmWTvM41wCrgHuB2YAXwjf0fsiRJ0tyy1yNcVXU38Pxkz3VHqf45cOOeXiPJAuC1VfXnNfjyxhuA9+3/cCVJkuae6a7hegewraqeHGo7Nsl3knwryTu6toXA+FCf8a5tUklWJVmfZP2OHTumOURJkqTRmm7guoAfP7q1FTimqk4GfhX4SpLXApOt16rdvWhVra6q5VW1fGxsl0tZSJIkzSlTvg5XkkOAXwDeNtFWVS8CL3bb9yd5CjiewRGtRUO7LwK2TLW2JEnSXDKdI1w/BzxeVX87VZhkLMm8bvtNwFLg6araCvwoyWnduq8PArdNo7YkSdKcsdcjXEluBM4AjkoyDlxeVdcCK9l1sfzpwKeTvAS8DHy0qiYW3H+MwRmPr2ZwdqJnKErSLLDkkq/3Umfzlef0UkeajfYauKrqgt20/6tJ2m4BbtlN//XAifs5PkmSpDnPK81LkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjew1cSdYk2Z5k41Dbp5I8l2RDdzt76LlLk2xK8kSS9wy1r+jaNiW5ZObfiiRJ0uy0L0e4rgNWTNJ+dVUt6263AyQ5AVgJvKXb578kmZdkHvC7wFnACcAFXV9JkqQD3iF761BVdydZso+vdx5wU1W9CHw3ySbg1O65TVX1NECSm7q+j+73iCVJkuaY6azhujjJQ92U4/yubSHw7FCf8a5td+2TSrIqyfok63fs2DGNIUqSJI3eVAPXNcBxwDJgK3BV155J+tYe2idVVauranlVLR8bG5viECVJkmaHvU4pTqaqtk1sJ/ki8LXu4TiweKjrImBLt727dkmSpAPalI5wJVkw9PB8YOIMxrXAyiSHJTkWWArcC9wHLE1ybJJDGSysXzv1YUuSJM0dez3CleRG4AzgqCTjwOXAGUmWMZgW3Ax8BKCqHklyM4PF8C8BF1XVy93rXAzcAcwD1lTVIzP+biRJkmahfTlL8YJJmq/dQ/8rgCsmab8duH2/RidJknQA8ErzkiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLU2F4DV5I1SbYn2TjU9pkkjyd5KMmtSY7s2pck+askG7rbF4b2eVuSh5NsSvL5JGnzliRJkmaXfTnCdR2wYqe2dcCJVXUS8BfApUPPPVVVy7rbR4farwFWAUu7286vKUmSdEDaa+CqqruB53dqu7OqXuoe3gMs2tNrJFkAvLaq/ryqCrgBeN/UhixJkjS3zMQarl8CvjH0+Ngk30nyrSTv6NoWAuNDfca7tkklWZVkfZL1O3bsmIEhSpIkjc60AleSy4CXgC93TVuBY6rqZOBXga8keS0w2Xqt2t3rVtXqqlpeVcvHxsamM0RJkqSRO2SqOya5EHgvcGY3TUhVvQi82G3fn+Qp4HgGR7SGpx0XAVumWluSJGkumdIRriQrgE8C51bVC0PtY0nmddtvYrA4/umq2gr8KMlp3dmJHwRum/boJUmS5oC9HuFKciNwBnBUknHgcgZnJR4GrOuu7nBPd0bi6cCnk7wEvAx8tKomFtx/jMEZj69msOZreN2XJEnSAWuvgauqLpik+drd9L0FuGU3z60HTtyv0UmSJB0AvNK8JElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1tk+BK8maJNuTbBxqe12SdUme7O7nd+1J8vkkm5I8lOSUoX0u7Po/meTCmX87kiRJs8++HuG6DlixU9slwF1VtRS4q3sMcBawtLutAq6BQUADLgd+FjgVuHwipEmSJB3I9ilwVdXdwPM7NZ8HXN9tXw+8b6j9hhq4BzgyyQLgPcC6qnq+qv43sI5dQ5wkSdIB55Bp7PuGqtoKUFVbkxzdtS8Enh3qN9617a59F0lWMTg6xjHHHDONIc4NSy75ei91Nl95Ti91JEnSj2uxaD6TtNUe2ndtrFpdVcuravnY2NiMDk6SJKlv0wlc27qpQrr77V37OLB4qN8iYMse2iVJkg5o0wlca4GJMw0vBG4bav9gd7biacAPuqnHO4B3J5nfLZZ/d9cmSZJ0QNunNVxJbgTOAI5KMs7gbMMrgZuTfBh4Bnh/1/124GxgE/AC8CGAqno+yW8B93X9Pl1VOy/ElyRJOuDsU+Cqqgt289SZk/Qt4KLdvM4aYM0+j06SJOkA4JXmJUmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY3t04VPJUlSG0su+XovdTZfeU4vdTQ5j3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqbEpB64kb06yYej2wySfSPKpJM8NtZ89tM+lSTYleSLJe2bmLUiSJM1uh0x1x6p6AlgGkGQe8BxwK/Ah4Oqq+uxw/yQnACuBtwBvBP40yfFV9fJUxyBJkjQXzNSU4pnAU1X1vT30OQ+4qaperKrvApuAU2eoviRJ0qw1U4FrJXDj0OOLkzyUZE2S+V3bQuDZoT7jXdsukqxKsj7J+h07dszQECVJkkZj2oEryaHAucAfdU3XAMcxmG7cClw10XWS3Wuy16yq1VW1vKqWj42NTXeIkiRJIzUTR7jOAh6oqm0AVbWtql6uqleAL/J304bjwOKh/RYBW2agviRJ0qw2E4HrAoamE5MsGHrufGBjt70WWJnksCTHAkuBe2egviRJ0qw25bMUAZIcDvw88JGh5t9OsozBdOHmieeq6pEkNwOPAi8BF3mGoiRJOhhMK3BV1QvA63dq+8Ae+l8BXDGdmpIkSXONV5qXJElqzMAlSZLUmIFLkiSpsWmt4ZIkTd+SS77eS53NV57TSx1Ju/IIlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmN+V2K8nvcJElqzCNckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1Ni0A1eSzUkeTrIhyfqu7XVJ1iV5sruf37UnyeeTbEryUJJTpltfkiRptpupI1zvrKplVbW8e3wJcFdVLQXu6h4DnAUs7W6rgGtmqL4kSdKs1eo6XOcBZ3Tb1wN/Bnyya7+hqgq4J8mRSRZU1dZG45BmPa+DJkkHvpk4wlXAnUnuT7Kqa3vDRIjq7o/u2hcCzw7tO961SZIkHbBm4gjX26tqS5KjgXVJHt9D30zSVrt0GgS3VQDHHHPMDAxRkiRpdKZ9hKuqtnT324FbgVOBbUkWAHT327vu48Diod0XAVsmec3VVbW8qpaPjY1Nd4iSJEkjNa3AleSIJK+Z2AbeDWwE1gIXdt0uBG7rttcCH+zOVjwN+IHrtyRJ0oFuulOKbwBuTTLxWl+pqm8muQ+4OcmHgWeA93f9bwfOBjYBLwAfmmZ9SZKkWW9agauqngbeOkn7XwJnTtJewEXTqSlJkjTXeKV5SZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaqzVdylKkrRP/D5RHQw8wiVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzAuf6qDnRRdHr4+fgX/+kkbJI1ySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSY1O+DleSxcANwE8BrwCrq+pzST4F/DKwo+v661V1e7fPpcCHgZeBX6mqO6YxdkmSNE1ei7Af07nw6UvAr1XVA0leA9yfZF333NVV9dnhzklOAFYCbwHeCPxpkuOr6uVpjEGSJGnWm/KUYlVtraoHuu0fAY8BC/ewy3nATVX1YlV9F9gEnDrV+pIkSXPFjKzhSrIEOBn4dtd0cZKHkqxJMr9rWwg8O7TbOLsJaElWJVmfZP2OHTsm6yJJkjRnTDtwJflJ4BbgE1X1Q+Aa4DhgGbAVuGqi6yS712SvWVWrq2p5VS0fGxub7hAlSZJGalqBK8mrGIStL1fVVwGqaltVvVxVrwBf5O+mDceBxUO7LwK2TKe+JEnSXDDlwJUkwLXAY1X1O0PtC4a6nQ9s7LbXAiuTHJbkWGApcO9U60uSJM0V0zlL8e3AB4CHk2zo2n4duCDJMgbThZuBjwBU1SNJbgYeZXCG40WeoShJkg4GUw5cVfU/mXxd1u172OcK4Iqp1pQkSZqLvNK8JElSYwYuSZKkxgxckiRJjRm4JEmSGpvOWYrSjPCLUyVJBzqPcEmSJDXmES5J0kHNo+zqg0e4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhrzSvOSJGmk+rja/6iv9O8RLkmSpMYMXJIkSY0ZuCRJkhpzDRd+U7wkSWqr98CVZAXwOWAe8KWqurLvMUj6cQfDglVJGqVeA1eSecDvAj8PjAP3JVlbVY/2OQ5JGmbglNRa32u4TgU2VdXTVfXXwE3AeT2PQZIkqVepqv6KJf8MWFFV/7p7/AHgZ6vq4p36rQJWdQ/fDDzR2yD33VHA961vfesftGOwvvWtf/DW35OfrqqxnRv7XsOVSdp2SXxVtRpY3X44U5dkfVUtt771rX9wjsH61rf+wVt/KvqeUhwHFg89XgRs6XkMkiRJveo7cN0HLE1ybJJDgZXA2p7HIEmS1KtepxSr6qUkFwN3MLgsxJqqeqTPMcygUU95Wt/6B3N9GP0YrG996x+89fdbr4vmJUmSDkZ+tY8kSVJjBi5JkqTGDFz7KcmaJNuTbBxB7cVJ/nuSx5I8kuTjIxjDTyS5N8mD3Rh+cwRjmJfkO0m+1nftrv7mJA8n2ZBk/QjqH5nkj5M83v0u/KMea7+5e98Ttx8m+URf9bsx/Nvud29jkhuT/ETP9T/e1X6kr/c+2edOktclWZfkye5+fs/139/9GbySpOnp+bup/5nu78BDSW5NcmTP9X+rq70hyZ1J3thn/aHn/l2SSnJUn/WTfCrJc0OfBWf3Wb9r/zdJnuh+D3+7Vf2ZYuDaf9cBK0ZU+yXg16rqZ4DTgIuSnNDzGF4E3lVVbwWWASuSnNbzGD4OPNZzzZ29s6qWjeg6MJ8DvllV/wB4Kz3+WVTVE937Xga8DXgBuLWv+kkWAr8CLK+qExmcfLOyx/onAr/M4Fsz3gq8N8nSHkpfx66fO5cAd1XVUuCu7nGf9TcCvwDc3bDunuqvA06sqpOAvwAu7bn+Z6rqpO7vwteA3+i5PkkWM/iqvGca1t5tfeDqic+Dqrq9z/pJ3sngm2pOqqq3AJ9tWH9GGLj2U1XdDTw/otpbq+qBbvtHDP6hXdjzGKqq/m/38FXdrbczL5IsAs4BvtRXzdkkyWuB04FrAarqr6vq/4xoOGcCT1XV93quewjw6iSHAIfT77X8fga4p6peqKqXgG8B57cuupvPnfOA67vt64H39Vm/qh6rql6+BWQ39e/sfgYA9zC4rmOf9X849PAIGn4O7uHfnauB/9Cy9l7q92I39T8GXFlVL3Z9tvc+sP1k4JqjkiwBTga+PYLa85JsALYD66qqzzH8JwYfMK/0WHNnBdyZ5P7ua6j69CZgB/B73bTql5Ic0fMYJqwEbuyzYFU9x+B/ss8AW4EfVNWdPQ5hI3B6ktcnORw4mx+/mHOf3lBVW2HwnzHg6BGNYzb4JeAbfRdNckWSZ4FfpO0Rrslqnws8V1UP9ll3Jxd306prWk5p78bxwDuSfDvJt5L8w57r7zcD1xyU5CeBW4BP7PS/rF5U1cvdYfRFwKndNEtzSd4LbK+q+/uotwdvr6pTgLMYTOue3mPtQ4BTgGuq6mTg/9F2KmlS3YWLzwX+qOe68xkc2TkWeCNwRJJ/2Vf9qnoM+I8MprO+CTzIYKpfI5LkMgY/gy/3XbuqLquqxV3ti/fWf6Z0Yf8yeg55O7kGOI7B0pKtwFU91z8EmM9gec2/B25OMtnXB84aBq45JsmrGIStL1fVV0c5lm4q68/ob03b24Fzk2wGbgLeleQPeqr9t6pqS3e/ncH6pVN7LD8OjA8dVfxjBgGsb2cBD1TVtp7r/hzw3araUVV/A3wV+Md9DqCqrq2qU6rqdAbTHE/2WX/ItiQLALr7WT+lMtOSXAi8F/jFGu1FJb8C/NMe6x3H4D8dD3afh4uAB5L8VF8DqKpt3X++XwG+SL+fgzD4LPxqt8zlXgazHs1OHJgJBq45pEvv1wKPVdXvjGgMYxNnAyV5NYN/AB/vo3ZVXVpVi6pqCYPprP9WVb0d3QBIckSS10xsA+9mMM3Ui6r6X8CzSd7cNZ0JPNpX/SEX0PN0YucZ4LQkh3d/H86k5xMokhzd3R/DYNH4KP4cYPC1aBd22xcCt41oHCORZAXwSeDcqnphBPWHT5Y4l54+BwGq6uGqOrqqlnSfh+PAKd3nQy8mwn7nfHr8HOz8CfCubizHA4cC3+95DPunqrztx43Bh+tW4G8Y/JJ/uMfa/4TB+qGHgA3d7eye3/9JwHe6MWwEfmNEP4czgK+NoO6bGEwjPQg8Alw2gjEsA9Z3P4M/Aeb3XP9w4C+Bvz+in/1vMvjHbSPw+8BhPdf/HwxC7oPAmT3V3OVzB3g9g7MTn+zuX9dz/fO77ReBbcAdPdffBDw79Fn4hZ7r39L9Dj4E/FdgYZ/1d3p+M3BUz+//94GHu/e/FljQc/1DgT/ofgYPMDh7vkn9mbr51T6SJEmNOaUoSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNfb/AV1GVOzPI6F9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies:  [14, 428, 249, 71, 145, 219, 8, 143, 6, 292, 737, 178, 61, 380, 116, 28]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAD4CAYAAAAuLKioAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAVkklEQVR4nO3df5Bd5X3f8fenyNiGxBY/FkoktbIThTj1mB9RqVJaJkZJhh8ehFszg8cNGkqrTgenuEmbyPVMWk/bGdy0IWGmQ4cax8Jx7BBsgoqpAyPbcTtTsJffYNlFphitpaD1D3ASJraJv/3jPhovYmFX6LnnXknv18ydc85znrvf565Wdz97nnPPSVUhSZKkQ/fXJj0ASZKkI4XBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ2smPQAAE4++eRau3btpIchSZK0pPvuu+8bVTWz2L6pCFZr165ldnZ20sOQJElaUpKvvdQ+pwIlSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOpmKK69LksZr7dZPDVLnyWsvHqSONK08YiVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6WTJYJTk9yYMLHt9J8p4kJya5O8njbXlC658k1yfZleThJGeP/2VIkiRN3pLBqqq+UlVnVtWZwM8AzwG3AVuBHVW1DtjRtgEuBNa1xxbghnEMXJIkadoc7FTgRuCrVfU1YBOwrbVvAy5t65uAm2vkHmBlktO6jFaSJGmKHWywuhz4WFs/tar2ArTlKa19FbB7wXPmWtsLJNmSZDbJ7Pz8/EEOQ5IkafosO1glORa4BPjDpbou0lYvaqi6sarWV9X6mZmZ5Q5DkiRpah3MEasLgfur6um2/fT+Kb623Nfa54A1C563GthzqAOVJEmadgcTrN7JD6cBAbYDm9v6ZuD2Be1XtE8HbgCe3T9lKEmSdCRbsZxOSY4DfgH4ZwuarwVuSXIV8BRwWWu/E7gI2MXoE4RXdhutJEnSFFtWsKqq54CTDmj7JqNPCR7Yt4Cru4xOkiTpMOKV1yVJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6mRZwSrJyiS3Jvlykp1JfjbJiUnuTvJ4W57Q+ibJ9Ul2JXk4ydnjfQmSJEnTYblHrH4H+HRV/RRwBrAT2ArsqKp1wI62DXAhsK49tgA3dB2xJEnSlFoyWCV5HXAecBNAVX2vqp4BNgHbWrdtwKVtfRNwc43cA6xMclr3kUuSJE2Z5RyxeiMwD/xukgeSfDDJ8cCpVbUXoC1Paf1XAbsXPH+utb1Aki1JZpPMzs/PH9KLkCRJmgbLCVYrgLOBG6rqLOAv+OG032KySFu9qKHqxqpaX1XrZ2ZmljVYSZKkabacYDUHzFXVvW37VkZB6+n9U3xtuW9B/zULnr8a2NNnuJIkSdNryWBVVX8K7E5yemvaCHwJ2A5sbm2bgdvb+nbgivbpwA3As/unDCVJko5kK5bZ75eBjyY5FngCuJJRKLslyVXAU8Blre+dwEXALuC51leSJOmIt6xgVVUPAusX2bVxkb4FXH2I45IkSTrseOV1SZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6WVawSvJkkkeSPJhktrWdmOTuJI+35QmtPUmuT7IrycNJzh7nC5AkSZoWB3PE6q1VdWZVrW/bW4EdVbUO2NG2AS4E1rXHFuCGXoOVJEmaZocyFbgJ2NbWtwGXLmi/uUbuAVYmOe0Q6kiSJB0WlhusCrgryX1JtrS2U6tqL0BbntLaVwG7Fzx3rrW9QJItSWaTzM7Pz7+y0UuSJE2RFcvsd25V7UlyCnB3ki+/TN8s0lYvaqi6EbgRYP369S/aL0mSdLhZ1hGrqtrTlvuA24BzgKf3T/G15b7WfQ5Ys+Dpq4E9vQYsSZI0rZYMVkmOT/Kj+9eBXwQeBbYDm1u3zcDtbX07cEX7dOAG4Nn9U4aSJElHsuVMBZ4K3JZkf//fr6pPJ/kicEuSq4CngMta/zuBi4BdwHPAld1HLUmSNIWWDFZV9QRwxiLt3wQ2LtJewNVdRidJknQY8crrkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInKyY9gKPJ2q2fGnuNJ6+9eOw1JEnS4jxiJUmS1InBSpIkqRODlSRJUifLDlZJjknyQJI72vYbktyb5PEkf5Dk2Nb+6ra9q+1fO56hS5IkTZeDOWJ1DbBzwfYHgOuqah3wbeCq1n4V8O2q+gngutZPkiTpiLesYJVkNXAx8MG2HeB84NbWZRtwaVvf1LZp+ze2/pIkSUe05R6x+m3g14AftO2TgGeq6vm2PQesauurgN0Abf+zrf8LJNmSZDbJ7Pz8/CscviRJ0vRYMlgleRuwr6ruW9i8SNdaxr4fNlTdWFXrq2r9zMzMsgYrSZI0zZZzgdBzgUuSXAS8BngdoyNYK5OsaEelVgN7Wv85YA0wl2QF8HrgW91HLkmSNGWWPGJVVe+tqtVVtRa4HPhMVb0L+CzwjtZtM3B7W9/etmn7P1NVLzpiJUmSdKQ5lOtY/TrwK0l2MTqH6qbWfhNwUmv/FWDroQ1RkiTp8HBQ9wqsqs8Bn2vrTwDnLNLnL4HLOoxNkiTpsOJNmCVJGsDarZ8ae40nr7147DX08ryljSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTpYMVklek+QLSR5K8liS97f2NyS5N8njSf4gybGt/dVte1fbv3a8L0GSJGk6LOeI1XeB86vqDOBM4IIkG4APANdV1Trg28BVrf9VwLer6ieA61o/SZKkI96SwapG/rxtvqo9CjgfuLW1bwMubeub2jZt/8Yk6TZiSZKkKbWsc6ySHJPkQWAfcDfwVeCZqnq+dZkDVrX1VcBugLb/WeCknoOWJEmaRssKVlX1V1V1JrAaOAd402Ld2nKxo1N1YEOSLUlmk8zOz88vd7ySJElT66A+FVhVzwCfAzYAK5OsaLtWA3va+hywBqDtfz3wrUW+1o1Vtb6q1s/MzLyy0UuSJE2RFUt1SDIDfL+qnknyWuDnGZ2Q/lngHcDHgc3A7e0p29v2/2n7P1NVLzpiJUlHk7VbPzVInSevvXiQOpIWt2SwAk4DtiU5htERrluq6o4kXwI+nuQ/AA8AN7X+NwEfSbKL0ZGqy8cwbkmSpKmzZLCqqoeBsxZpf4LR+VYHtv8lcFmX0UmSJB1GvPK6JElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUifLuaWNjhBD3KvM+5RJko5mHrGSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOvE6VtJAhriOGHgtMUmaJI9YSZIkdbJksEqyJslnk+xM8liSa1r7iUnuTvJ4W57Q2pPk+iS7kjyc5OxxvwhJkqRpsJwjVs8Dv1pVbwI2AFcn+WlgK7CjqtYBO9o2wIXAuvbYAtzQfdSSJElTaMlgVVV7q+r+tv5nwE5gFbAJ2Na6bQMubeubgJtr5B5gZZLTuo9ckiRpyhzUOVZJ1gJnAfcCp1bVXhiFL+CU1m0VsHvB0+ZamyRJ0hFt2cEqyY8AnwDeU1Xfebmui7TVIl9vS5LZJLPz8/PLHYYkSdLUWlawSvIqRqHqo1X1ydb89P4pvrbc19rngDULnr4a2HPg16yqG6tqfVWtn5mZeaXjlyRJmhrL+VRggJuAnVX1Wwt2bQc2t/XNwO0L2q9onw7cADy7f8pQkiTpSLacC4SeC/wS8EiSB1vbvwGuBW5JchXwFHBZ23cncBGwC3gOuLLriCVJkqbUksGqqv43i583BbBxkf4FXH2I45IkSTrseOV1SZKkTrxXoCRpEEPcL9N7ZWrSPGIlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sQLhOqoMcTFCcELFErS0cxgJWkQBltJRwOnAiVJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInXm5BkqSjgJc8GYZHrCRJkjpZMlgl+VCSfUkeXdB2YpK7kzzelie09iS5PsmuJA8nOXucg5ckSZomyzli9WHgggPatgI7qmodsKNtA1wIrGuPLcANfYYpSZI0/ZYMVlX1eeBbBzRvAra19W3ApQvab66Re4CVSU7rNVhJkqRp9krPsTq1qvYCtOUprX0VsHtBv7nW9iJJtiSZTTI7Pz//CochSZI0PXqfvJ5F2mqxjlV1Y1Wtr6r1MzMznYchSZI0vFcarJ7eP8XXlvta+xywZkG/1cCeVz48SZKkw8crDVbbgc1tfTNw+4L2K9qnAzcAz+6fMpQkSTrSLXmB0CQfA34OODnJHPBvgWuBW5JcBTwFXNa63wlcBOwCngOuHMOYJUmSptKSwaqq3vkSuzYu0reAqw91UJIkSYcjr7wuSZLUicFKkiSpE2/CrMEMcQPQo/3mn5KkyfKIlSRJUicGK0mSpE6cCpQkHRU8HUFD8IiVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRMvECpJksZuiAu0wuQv0uoRK0mSpE4MVpIkSZ0YrCRJkjo5as6xOlrmdiVJ0uSM5YhVkguSfCXJriRbx1FDkiRp2nQ/YpXkGOC/Ar8AzAFfTLK9qr7Uu5ak5Tvaj9oe7a9f0jDGccTqHGBXVT1RVd8DPg5sGkMdSZKkqZKq6vsFk3cAF1TVP2nbvwT8nap69wH9tgBb2ubpwFe6DqSPk4FvWH+iJj0G61vf+kdv/WkYg/Un/zOwmL9ZVTOL7RjHyetZpO1F6a2qbgRuHEP9bpLMVtV660/OpMdgfetb/+itPw1jsP7kfwYO1jimAueANQu2VwN7xlBHkiRpqowjWH0RWJfkDUmOBS4Hto+hjiRJ0lTpPhVYVc8neTfwx8AxwIeq6rHedQYy6anKo70+TH4M1re+9Y/e+jD5MVj/MNP95HVJkqSjlbe0kSRJ6sRgJUmS1InBahFJPpRkX5JHJ1R/TZLPJtmZ5LEk1wxc/zVJvpDkoVb//UPWXzCOY5I8kOSOCdR+MskjSR5MMjuB+iuT3Jrky+3n4GcHrn96e+37H99J8p6Bx/Av28/fo0k+luQ1A9e/ptV+bIjXvtj7TpITk9yd5PG2PGHg+pe11/+DJGP9yPtL1P/N9n/g4SS3JVk5cP1/32o/mOSuJD82ZP0F+/5Vkkpy8rjqv9QYkvy7JF9f8F5w0ZD1W/svt9vkPZbkP42rfi8Gq8V9GLhggvWfB361qt4EbACuTvLTA9b/LnB+VZ0BnAlckGTDgPX3uwbYOYG6+721qs6c0DVUfgf4dFX9FHAGA38fquor7bWfCfwM8Bxw21D1k6wC/gWwvqrezOiDMJcPWP/NwD9ldCeJM4C3JVk35rIf5sXvO1uBHVW1DtjRtoes/yjwD4DPj7Huy9W/G3hzVb0F+L/Aeweu/5tV9Zb2/+AO4DcGrk+SNYxuEffUGGu/7BiA6/a/H1TVnUPWT/JWRndveUtV/S3gP4+xfhcGq0VU1eeBb02w/t6qur+t/xmjX6qrBqxfVfXnbfNV7THopxySrAYuBj44ZN1pkOR1wHnATQBV9b2qemaCQ9oIfLWqvjZw3RXAa5OsAI5j2OvhvQm4p6qeq6rngT8B3j7Ogi/xvrMJ2NbWtwGXDlm/qnZW1SB3xXiJ+ne17z/APYyuizhk/e8s2DyeMb4PvszvneuAXxtn7WWMYRAvUf+fA9dW1Xdbn32DD+wgGaymXJK1wFnAvQPXPSbJg8A+4O6qGrQ+8NuM3kx+MHDd/Qq4K8l97fZLQ3ojMA/8bpsK/WCS4wcew0KXAx8bsmBVfZ3RX6ZPAXuBZ6vqrgGH8ChwXpKTkhwHXMQLL3w8lFOrai+M/uACTpnAGKbFPwb+59BFk/zHJLuBdzHeI1aL1b4E+HpVPTRk3UW8u02Jfmic09Ev4SeBv5/k3iR/kuRvD1z/oBmspliSHwE+AbzngL+cxq6q/qod/l4NnNOmRgaR5G3Avqq6b6iaizi3qs4GLmQ0FXvegLVXAGcDN1TVWcBfMN4poJfULvJ7CfCHA9c9gdHRmjcAPwYcn+QfDVW/qnYCH2A0FfVp4CFGU/SagCTvY/T9/+jQtavqfVW1ptV+91L9e2mB/n0MHOYWcQPw44xOC9kL/JeB668ATmB0Wsy/Bm5Jstit86aGwWpKJXkVo1D10ar65KTG0aagPsew55ydC1yS5Eng48D5SX5vwPpU1Z623Mfo3KJzBiw/B8wtOEp4K6OgNQkXAvdX1dMD1/154P9V1XxVfR/4JPB3hxxAVd1UVWdX1XmMpiceH7J+83SS0wDacuqnQXpLshl4G/CumuyFF38f+IcD1vtxRn9YPNTeC1cD9yf56wOOgap6uv2h/QPgvzPseyGM3g8/2U5R+QKjWYyxnsR/qAxWU6il8ZuAnVX1WxOoP7P/0zdJXsvol9yXh6pfVe+tqtVVtZbRNNRnqmqwoxVJjk/yo/vXgV9kNDU0iKr6U2B3ktNb00bgS0PVP8A7GXgasHkK2JDkuPb/YSMDn8Cf5JS2/BuMTuCexPdhO7C5rW8Gbp/AGCYmyQXArwOXVNVzE6i/8AMLlzDs++AjVXVKVa1t74VzwNnt/WEw+4N983YGfC9s/gg4v43lJ4FjgW8MPIaDU1U+DngwegPdC3yf0Q/zVQPX/3uMzvF5GHiwPS4asP5bgAda/UeB35jgv8XPAXcMXPONjKZ+HgIeA943gdd9JjDb/g3+CDhhAmM4Dvgm8PoJ/du/n9EvskeBjwCvHrj+/2IUaB8CNg5Q70XvO8BJjD4N+Hhbnjhw/be39e8CTwN/PHD9XcDuBe+D/23g+p9oP38PA/8DWDVk/QP2PwmcPIGfwY8Aj7TvwXbgtIHrHwv8Xvt3uJ/RJ9bH9j3o8fCWNpIkSZ04FShJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR18v8Bip7g564yVfIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'C:\\\\Users\\\\spele\\\\Miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split to training and test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=69, stratify=y)\n",
    "\n",
    "# Normalisation\n",
    "sc = preprocessing.MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.fit_transform(X_val)\n",
    "\n",
    "# Split training set to training and validation set\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=69, stratify=y_train)\n",
    "print('Training set shape      : ', X_train.shape)\n",
    "print('Training labels shape   : ', y_train.shape)\n",
    "print('Validation set shape    : ', X_val.shape)\n",
    "print('Validation labels shape : ', y_val.shape)\n",
    "#print('Test set shape          : ', X_test.shape)\n",
    "hist(y_train)\n",
    "hist(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = IndianPineArray(X_train, y_train)\n",
    "val = IndianPineArray(X_val, y_val)\n",
    "#test = IndianPineArray(X_test, y_test)\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=128, num_workers=0)\n",
    "valloader = DataLoader(val, batch_size=128, num_workers=0)\n",
    "#testloader = DataLoader(test, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a data batch as fetched by the dataloader of the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, {'bands': tensor([[0.4662, 0.4056, 0.1537,  ..., 0.2245, 0.3710, 0.4694],\n",
       "          [0.1182, 0.4499, 0.1238,  ..., 0.1633, 0.3065, 0.4082],\n",
       "          [0.3589, 0.4024, 0.1156,  ..., 0.2143, 0.2903, 0.3878],\n",
       "          ...,\n",
       "          [0.6831, 0.7328, 0.6493,  ..., 0.5102, 0.4032, 0.4898],\n",
       "          [0.0268, 0.5847, 0.2441,  ..., 0.6531, 0.6129, 0.5918],\n",
       "          [0.0165, 0.5872, 0.3310,  ..., 0.7959, 0.6129, 0.5714]],\n",
       "         dtype=torch.float64),\n",
       "  'labels': tensor([14,  6, 14,  3, 14, 14,  2,  3,  3,  3,  2, 11, 14, 10,  4,  8, 11, 14,\n",
       "           8, 12, 11, 14, 11, 14, 11, 11, 14, 15,  1,  2,  6, 14,  8, 12, 11, 16,\n",
       "          10, 11, 11, 11, 11, 10,  6, 11,  6, 11,  8, 10,  6,  3, 14,  2, 12, 15,\n",
       "          16, 15,  3, 14,  3,  2,  3, 11, 11, 14,  5, 14, 10, 10,  2, 11,  2, 13,\n",
       "           2,  2, 11,  5,  5, 10,  6, 14, 12, 11, 14,  3, 11,  2, 13,  8,  2,  3,\n",
       "          11, 11,  2, 11,  3, 11, 11,  5, 11, 11, 15, 11,  2, 12,  6, 14,  3,  2,\n",
       "           5, 15,  3, 13, 11,  2,  6, 14,  5,  2, 14, 13, 11, 11, 14,  2, 12, 16,\n",
       "           3,  4])})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(trainloader))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP1, self).__init__()\n",
    "        self.fc1 = nn.Linear(200, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 16)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        logits = self.fc4(x)\n",
    "        return logits\n",
    "\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, self.output_dim)\n",
    "        )\n",
    "         \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x.float())\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also check if gpu is available in order to process the tensors in the appropriate device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cuda\n",
    "# =============================================================================\n",
    "cuda = torch.cuda.is_available()\n",
    "torch.cuda.empty_cache()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation process of the models\n",
    "In this section I instantiate the models, I choose loss function (Cross Entropy Loss) and the optimizer (Adam)\n",
    "I also train the NNs. I also use the validation set in order to locate the appropriate number of epochs that prevents overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def logit_accuracy(logits, y_true):\n",
    "    max_vals, max_indices = torch.max(logits, 1)\n",
    "    acc = (max_indices == y_true).sum().item()/max_indices.size()[0]\n",
    "    return acc, y_true, max_indices\n",
    "\n",
    "def trainNN (model, patience, best_model_name, epochs, trainloader, valloader, device,\n",
    "             optimizer, criterion):\n",
    "    # Initialisations\n",
    "    epoch = 0\n",
    "    epoch_loss_val = []\n",
    "    epoch_loss_train = []\n",
    "    countdown = patience    \n",
    "\n",
    "    # Training\n",
    "    while epoch < epochs and countdown > 0:\n",
    "        # Training\n",
    "        epoch +=1\n",
    "        batch_loss = []\n",
    "        y_pred = []\n",
    "        batch_acc = []\n",
    "        # enumerate fetches a batch of the data for training!\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs = data['bands'].to(device)\n",
    "            labels = data['labels'].long().to(device)\n",
    "            # reset gradients for each batch\n",
    "            optimizer.zero_grad()\n",
    "            # forward step\n",
    "            out = model(inputs.float())\n",
    "            # compute loss and save it to list\n",
    "            loss = criterion(out, labels)\n",
    "            batch_loss.append(loss.item())\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # update weights according to the selected optimizer\n",
    "            optimizer.step()\n",
    "            # calculate batch accuracy for this epoch\n",
    "            batch_acc.append(logit_accuracy(out, labels)[0])\n",
    "        print(\"Epoch: {}:\\nTraining loss  : {:.5f}, Training accuracy  : {:.3f}\".\n",
    "            format(epoch, np.mean(batch_loss), np.mean(batch_acc)))\n",
    "        epoch_loss_train.append(np.mean(batch_loss))\n",
    "        # Validation\n",
    "        batch_loss_val = []\n",
    "        batch_acc_val = []\n",
    "        y_pred_val = []\n",
    "        \n",
    "        # Validation\n",
    "        # no need to store gradients here (Validation purposes only)\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader):\n",
    "                inputs_val = data['bands'].to(device)\n",
    "                labels_val = data['labels'].long().to(device)\n",
    "                out_val = model(inputs_val.float())\n",
    "                loss_val = criterion(out_val, labels_val)\n",
    "                batch_loss_val.append(loss_val.item())\n",
    "                # calculate batch accuracy for this epoch\n",
    "                batch_acc_val.append(logit_accuracy(out_val, labels_val)[0])\n",
    "        epoch_loss_val.append(np.mean(batch_loss_val))\n",
    "        print(\"Validation loss: {:1.3f}, Validation accuracy: {:1.3f}\\nCountdown: {} \\n\".\n",
    "              format(epoch_loss_val[-1], np.mean(batch_acc_val), countdown))\n",
    "        # Early stopping condtion: N epochs without achieving loss less than the\n",
    "        # present minimum. No need to save models before patience\n",
    "        if epoch_loss_val[-1] <= min(epoch_loss_val):\n",
    "            countdown = patience #start countdown\n",
    "        #checkpoint \n",
    "            if epoch >= patience: # no need to save before that\n",
    "        #I ovewrite models so as to keep the last to trigger the countdown\n",
    "                torch.save(model, os.path.join(os.getcwd(),\n",
    "                        \"models\" + os.path.sep + best_model_name + \".pt\"))\n",
    "        else:\n",
    "            countdown -= 1\n",
    "    print(\"Finished Training!\")\n",
    "    # Plot Train / Validation Loss\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,4)\n",
    "    plt.figure()\n",
    "    plt.title(\"Relative Loss\")\n",
    "    plt.plot(list(range(1,epoch+1)), epoch_loss_train, label='Training set')\n",
    "    plt.plot(list(range(1,epoch+1)), epoch_loss_val,  label='Validation set')\n",
    "    plt.grid()\n",
    "    plt.ylim(0, 3)\n",
    "    plt.legend(fancybox=True)\n",
    "    plt.show()\n",
    "    return epoch_loss_train, epoch_loss_val, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP1(\n",
      "  (fc1): Linear(in_features=200, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=16, bias=True)\n",
      ")\n",
      "Epoch: 1:\n",
      "Training loss  : 1.70387, Training accuracy  : 0.399\n",
      "Validation loss: 1.798, Validation accuracy: 0.422\n",
      "Countdown: 500 \n",
      "\n",
      "Epoch: 2:\n",
      "Training loss  : 1.44300, Training accuracy  : 0.467\n",
      "Validation loss: 1.587, Validation accuracy: 0.468\n",
      "Countdown: 500 \n",
      "\n",
      "Epoch: 3:\n",
      "Training loss  : 1.39497, Training accuracy  : 0.477\n",
      "Validation loss: 1.615, Validation accuracy: 0.466\n",
      "Countdown: 500 \n",
      "\n",
      "Epoch: 4:\n",
      "Training loss  : 1.36347, Training accuracy  : 0.491\n",
      "Validation loss: 1.488, Validation accuracy: 0.503\n",
      "Countdown: 499 \n",
      "\n",
      "Epoch: 5:\n",
      "Training loss  : 1.31689, Training accuracy  : 0.513\n",
      "Validation loss: 1.572, Validation accuracy: 0.493\n",
      "Countdown: 500 \n",
      "\n",
      "Epoch: 6:\n",
      "Training loss  : 1.30839, Training accuracy  : 0.520\n",
      "Validation loss: 1.591, Validation accuracy: 0.501\n",
      "Countdown: 499 \n",
      "\n",
      "Epoch: 7:\n",
      "Training loss  : 1.25940, Training accuracy  : 0.533\n",
      "Validation loss: 1.769, Validation accuracy: 0.487\n",
      "Countdown: 498 \n",
      "\n",
      "Epoch: 8:\n",
      "Training loss  : 1.23565, Training accuracy  : 0.548\n",
      "Validation loss: 1.742, Validation accuracy: 0.490\n",
      "Countdown: 497 \n",
      "\n",
      "Epoch: 9:\n",
      "Training loss  : 1.18638, Training accuracy  : 0.571\n",
      "Validation loss: 1.825, Validation accuracy: 0.496\n",
      "Countdown: 496 \n",
      "\n",
      "Epoch: 10:\n",
      "Training loss  : 1.19916, Training accuracy  : 0.555\n",
      "Validation loss: 1.881, Validation accuracy: 0.492\n",
      "Countdown: 495 \n",
      "\n",
      "Epoch: 11:\n",
      "Training loss  : 1.08157, Training accuracy  : 0.600\n",
      "Validation loss: 1.947, Validation accuracy: 0.527\n",
      "Countdown: 494 \n",
      "\n",
      "Epoch: 12:\n",
      "Training loss  : 1.07107, Training accuracy  : 0.606\n",
      "Validation loss: 2.054, Validation accuracy: 0.508\n",
      "Countdown: 493 \n",
      "\n",
      "Epoch: 13:\n",
      "Training loss  : 0.98611, Training accuracy  : 0.627\n",
      "Validation loss: 2.215, Validation accuracy: 0.544\n",
      "Countdown: 492 \n",
      "\n",
      "Epoch: 14:\n",
      "Training loss  : 1.08066, Training accuracy  : 0.603\n",
      "Validation loss: 2.044, Validation accuracy: 0.484\n",
      "Countdown: 491 \n",
      "\n",
      "Epoch: 15:\n",
      "Training loss  : 0.94068, Training accuracy  : 0.644\n",
      "Validation loss: 1.916, Validation accuracy: 0.520\n",
      "Countdown: 490 \n",
      "\n",
      "Epoch: 16:\n",
      "Training loss  : 0.89409, Training accuracy  : 0.665\n",
      "Validation loss: 2.062, Validation accuracy: 0.501\n",
      "Countdown: 489 \n",
      "\n",
      "Epoch: 17:\n",
      "Training loss  : 0.86654, Training accuracy  : 0.683\n",
      "Validation loss: 2.361, Validation accuracy: 0.435\n",
      "Countdown: 488 \n",
      "\n",
      "Epoch: 18:\n",
      "Training loss  : 0.84935, Training accuracy  : 0.687\n",
      "Validation loss: 2.002, Validation accuracy: 0.439\n",
      "Countdown: 487 \n",
      "\n",
      "Epoch: 19:\n",
      "Training loss  : 0.79613, Training accuracy  : 0.711\n",
      "Validation loss: 2.310, Validation accuracy: 0.433\n",
      "Countdown: 486 \n",
      "\n",
      "Epoch: 20:\n",
      "Training loss  : 0.80862, Training accuracy  : 0.700\n",
      "Validation loss: 2.418, Validation accuracy: 0.411\n",
      "Countdown: 485 \n",
      "\n",
      "Epoch: 21:\n",
      "Training loss  : 0.75082, Training accuracy  : 0.737\n",
      "Validation loss: 2.118, Validation accuracy: 0.500\n",
      "Countdown: 484 \n",
      "\n",
      "Epoch: 22:\n",
      "Training loss  : 0.75379, Training accuracy  : 0.728\n",
      "Validation loss: 2.262, Validation accuracy: 0.525\n",
      "Countdown: 483 \n",
      "\n",
      "Epoch: 23:\n",
      "Training loss  : 0.67496, Training accuracy  : 0.761\n",
      "Validation loss: 1.928, Validation accuracy: 0.530\n",
      "Countdown: 482 \n",
      "\n",
      "Epoch: 24:\n",
      "Training loss  : 0.69267, Training accuracy  : 0.750\n",
      "Validation loss: 2.513, Validation accuracy: 0.447\n",
      "Countdown: 481 \n",
      "\n",
      "Epoch: 25:\n",
      "Training loss  : 0.66665, Training accuracy  : 0.759\n",
      "Validation loss: 2.412, Validation accuracy: 0.487\n",
      "Countdown: 480 \n",
      "\n",
      "Epoch: 26:\n",
      "Training loss  : 0.61941, Training accuracy  : 0.787\n",
      "Validation loss: 2.283, Validation accuracy: 0.544\n",
      "Countdown: 479 \n",
      "\n",
      "Epoch: 27:\n",
      "Training loss  : 0.65450, Training accuracy  : 0.769\n",
      "Validation loss: 2.300, Validation accuracy: 0.487\n",
      "Countdown: 478 \n",
      "\n",
      "Epoch: 28:\n",
      "Training loss  : 0.63810, Training accuracy  : 0.772\n",
      "Validation loss: 2.337, Validation accuracy: 0.545\n",
      "Countdown: 477 \n",
      "\n",
      "Epoch: 29:\n",
      "Training loss  : 0.58778, Training accuracy  : 0.796\n",
      "Validation loss: 2.509, Validation accuracy: 0.502\n",
      "Countdown: 476 \n",
      "\n",
      "Epoch: 30:\n",
      "Training loss  : 0.56304, Training accuracy  : 0.801\n",
      "Validation loss: 2.409, Validation accuracy: 0.522\n",
      "Countdown: 475 \n",
      "\n",
      "Epoch: 31:\n",
      "Training loss  : 0.56721, Training accuracy  : 0.796\n",
      "Validation loss: 2.344, Validation accuracy: 0.521\n",
      "Countdown: 474 \n",
      "\n",
      "Epoch: 32:\n",
      "Training loss  : 0.56582, Training accuracy  : 0.804\n",
      "Validation loss: 2.596, Validation accuracy: 0.522\n",
      "Countdown: 473 \n",
      "\n",
      "Epoch: 33:\n",
      "Training loss  : 0.61018, Training accuracy  : 0.778\n",
      "Validation loss: 2.679, Validation accuracy: 0.506\n",
      "Countdown: 472 \n",
      "\n",
      "Epoch: 34:\n",
      "Training loss  : 0.62206, Training accuracy  : 0.776\n",
      "Validation loss: 2.331, Validation accuracy: 0.529\n",
      "Countdown: 471 \n",
      "\n",
      "Epoch: 35:\n",
      "Training loss  : 0.60227, Training accuracy  : 0.786\n",
      "Validation loss: 2.581, Validation accuracy: 0.457\n",
      "Countdown: 470 \n",
      "\n",
      "Epoch: 36:\n",
      "Training loss  : 0.56487, Training accuracy  : 0.797\n",
      "Validation loss: 2.630, Validation accuracy: 0.474\n",
      "Countdown: 469 \n",
      "\n",
      "Epoch: 37:\n",
      "Training loss  : 0.53801, Training accuracy  : 0.812\n",
      "Validation loss: 2.541, Validation accuracy: 0.503\n",
      "Countdown: 468 \n",
      "\n",
      "Epoch: 38:\n",
      "Training loss  : 0.54488, Training accuracy  : 0.804\n",
      "Validation loss: 2.579, Validation accuracy: 0.494\n",
      "Countdown: 467 \n",
      "\n",
      "Epoch: 39:\n",
      "Training loss  : 0.56686, Training accuracy  : 0.793\n",
      "Validation loss: 2.437, Validation accuracy: 0.501\n",
      "Countdown: 466 \n",
      "\n",
      "Epoch: 40:\n",
      "Training loss  : 0.57365, Training accuracy  : 0.793\n",
      "Validation loss: 2.987, Validation accuracy: 0.437\n",
      "Countdown: 465 \n",
      "\n",
      "Epoch: 41:\n",
      "Training loss  : 0.55764, Training accuracy  : 0.802\n",
      "Validation loss: 2.812, Validation accuracy: 0.452\n",
      "Countdown: 464 \n",
      "\n",
      "Epoch: 42:\n",
      "Training loss  : 0.56577, Training accuracy  : 0.798\n",
      "Validation loss: 3.037, Validation accuracy: 0.457\n",
      "Countdown: 463 \n",
      "\n",
      "Epoch: 43:\n",
      "Training loss  : 0.53048, Training accuracy  : 0.809\n",
      "Validation loss: 2.721, Validation accuracy: 0.450\n",
      "Countdown: 462 \n",
      "\n",
      "Epoch: 44:\n",
      "Training loss  : 0.50768, Training accuracy  : 0.822\n",
      "Validation loss: 2.895, Validation accuracy: 0.491\n",
      "Countdown: 461 \n",
      "\n",
      "Epoch: 45:\n",
      "Training loss  : 0.50872, Training accuracy  : 0.815\n",
      "Validation loss: 2.836, Validation accuracy: 0.453\n",
      "Countdown: 460 \n",
      "\n",
      "Epoch: 46:\n",
      "Training loss  : 0.52334, Training accuracy  : 0.815\n",
      "Validation loss: 3.213, Validation accuracy: 0.416\n",
      "Countdown: 459 \n",
      "\n",
      "Epoch: 47:\n",
      "Training loss  : 0.51460, Training accuracy  : 0.820\n",
      "Validation loss: 3.132, Validation accuracy: 0.452\n",
      "Countdown: 458 \n",
      "\n",
      "Epoch: 48:\n",
      "Training loss  : 0.53542, Training accuracy  : 0.809\n",
      "Validation loss: 2.602, Validation accuracy: 0.490\n",
      "Countdown: 457 \n",
      "\n",
      "Epoch: 49:\n",
      "Training loss  : 0.48009, Training accuracy  : 0.832\n",
      "Validation loss: 3.041, Validation accuracy: 0.470\n",
      "Countdown: 456 \n",
      "\n",
      "Epoch: 50:\n",
      "Training loss  : 0.48146, Training accuracy  : 0.827\n",
      "Validation loss: 2.917, Validation accuracy: 0.487\n",
      "Countdown: 455 \n",
      "\n",
      "Epoch: 51:\n",
      "Training loss  : 0.43731, Training accuracy  : 0.846\n",
      "Validation loss: 2.850, Validation accuracy: 0.484\n",
      "Countdown: 454 \n",
      "\n",
      "Epoch: 52:\n",
      "Training loss  : 0.43872, Training accuracy  : 0.845\n",
      "Validation loss: 2.658, Validation accuracy: 0.522\n",
      "Countdown: 453 \n",
      "\n",
      "Epoch: 53:\n",
      "Training loss  : 0.47634, Training accuracy  : 0.831\n",
      "Validation loss: 3.204, Validation accuracy: 0.457\n",
      "Countdown: 452 \n",
      "\n",
      "Epoch: 54:\n",
      "Training loss  : 0.46318, Training accuracy  : 0.835\n",
      "Validation loss: 2.975, Validation accuracy: 0.487\n",
      "Countdown: 451 \n",
      "\n",
      "Epoch: 55:\n",
      "Training loss  : 0.46799, Training accuracy  : 0.836\n",
      "Validation loss: 2.691, Validation accuracy: 0.528\n",
      "Countdown: 450 \n",
      "\n",
      "Epoch: 56:\n",
      "Training loss  : 0.56248, Training accuracy  : 0.799\n",
      "Validation loss: 2.812, Validation accuracy: 0.500\n",
      "Countdown: 449 \n",
      "\n",
      "Epoch: 57:\n",
      "Training loss  : 0.48730, Training accuracy  : 0.833\n",
      "Validation loss: 2.745, Validation accuracy: 0.486\n",
      "Countdown: 448 \n",
      "\n",
      "Epoch: 58:\n",
      "Training loss  : 0.47833, Training accuracy  : 0.830\n",
      "Validation loss: 2.459, Validation accuracy: 0.544\n",
      "Countdown: 447 \n",
      "\n",
      "Epoch: 59:\n",
      "Training loss  : 0.49691, Training accuracy  : 0.824\n",
      "Validation loss: 2.493, Validation accuracy: 0.553\n",
      "Countdown: 446 \n",
      "\n",
      "Epoch: 60:\n",
      "Training loss  : 0.48866, Training accuracy  : 0.825\n",
      "Validation loss: 2.825, Validation accuracy: 0.514\n",
      "Countdown: 445 \n",
      "\n",
      "Epoch: 61:\n",
      "Training loss  : 0.44494, Training accuracy  : 0.840\n",
      "Validation loss: 2.681, Validation accuracy: 0.521\n",
      "Countdown: 444 \n",
      "\n",
      "Epoch: 62:\n",
      "Training loss  : 0.44634, Training accuracy  : 0.842\n",
      "Validation loss: 2.709, Validation accuracy: 0.521\n",
      "Countdown: 443 \n",
      "\n",
      "Epoch: 63:\n",
      "Training loss  : 0.44874, Training accuracy  : 0.841\n",
      "Validation loss: 3.094, Validation accuracy: 0.472\n",
      "Countdown: 442 \n",
      "\n",
      "Epoch: 64:\n",
      "Training loss  : 0.41617, Training accuracy  : 0.854\n",
      "Validation loss: 2.777, Validation accuracy: 0.512\n",
      "Countdown: 441 \n",
      "\n",
      "Epoch: 65:\n",
      "Training loss  : 0.39633, Training accuracy  : 0.858\n",
      "Validation loss: 2.993, Validation accuracy: 0.504\n",
      "Countdown: 440 \n",
      "\n",
      "Epoch: 66:\n",
      "Training loss  : 0.39225, Training accuracy  : 0.859\n",
      "Validation loss: 3.073, Validation accuracy: 0.507\n",
      "Countdown: 439 \n",
      "\n",
      "Epoch: 67:\n",
      "Training loss  : 0.41455, Training accuracy  : 0.852\n",
      "Validation loss: 2.994, Validation accuracy: 0.519\n",
      "Countdown: 438 \n",
      "\n",
      "Epoch: 68:\n",
      "Training loss  : 0.45349, Training accuracy  : 0.840\n",
      "Validation loss: 2.778, Validation accuracy: 0.512\n",
      "Countdown: 437 \n",
      "\n",
      "Epoch: 69:\n",
      "Training loss  : 0.41002, Training accuracy  : 0.857\n",
      "Validation loss: 3.067, Validation accuracy: 0.512\n",
      "Countdown: 436 \n",
      "\n",
      "Epoch: 70:\n",
      "Training loss  : 0.47089, Training accuracy  : 0.834\n",
      "Validation loss: 2.786, Validation accuracy: 0.517\n",
      "Countdown: 435 \n",
      "\n",
      "Epoch: 71:\n",
      "Training loss  : 0.39336, Training accuracy  : 0.863\n",
      "Validation loss: 3.105, Validation accuracy: 0.506\n",
      "Countdown: 434 \n",
      "\n",
      "Epoch: 72:\n",
      "Training loss  : 0.39941, Training accuracy  : 0.860\n",
      "Validation loss: 2.550, Validation accuracy: 0.527\n",
      "Countdown: 433 \n",
      "\n",
      "Epoch: 73:\n",
      "Training loss  : 0.44603, Training accuracy  : 0.838\n",
      "Validation loss: 3.578, Validation accuracy: 0.472\n",
      "Countdown: 432 \n",
      "\n",
      "Epoch: 74:\n",
      "Training loss  : 0.78267, Training accuracy  : 0.743\n",
      "Validation loss: 2.677, Validation accuracy: 0.518\n",
      "Countdown: 431 \n",
      "\n",
      "Epoch: 75:\n",
      "Training loss  : 0.44672, Training accuracy  : 0.841\n",
      "Validation loss: 3.111, Validation accuracy: 0.502\n",
      "Countdown: 430 \n",
      "\n",
      "Epoch: 76:\n",
      "Training loss  : 0.38709, Training accuracy  : 0.866\n",
      "Validation loss: 2.985, Validation accuracy: 0.493\n",
      "Countdown: 429 \n",
      "\n",
      "Epoch: 77:\n",
      "Training loss  : 0.38992, Training accuracy  : 0.867\n",
      "Validation loss: 3.187, Validation accuracy: 0.511\n",
      "Countdown: 428 \n",
      "\n",
      "Epoch: 78:\n",
      "Training loss  : 0.43405, Training accuracy  : 0.847\n",
      "Validation loss: 3.190, Validation accuracy: 0.529\n",
      "Countdown: 427 \n",
      "\n",
      "Epoch: 79:\n",
      "Training loss  : 0.44430, Training accuracy  : 0.841\n",
      "Validation loss: 3.116, Validation accuracy: 0.515\n",
      "Countdown: 426 \n",
      "\n",
      "Epoch: 80:\n",
      "Training loss  : 0.42969, Training accuracy  : 0.847\n",
      "Validation loss: 3.473, Validation accuracy: 0.508\n",
      "Countdown: 425 \n",
      "\n",
      "Epoch: 81:\n",
      "Training loss  : 0.40987, Training accuracy  : 0.852\n",
      "Validation loss: 3.366, Validation accuracy: 0.494\n",
      "Countdown: 424 \n",
      "\n",
      "Epoch: 82:\n",
      "Training loss  : 0.38950, Training accuracy  : 0.862\n",
      "Validation loss: 3.482, Validation accuracy: 0.495\n",
      "Countdown: 423 \n",
      "\n",
      "Epoch: 83:\n",
      "Training loss  : 0.40776, Training accuracy  : 0.852\n",
      "Validation loss: 4.076, Validation accuracy: 0.435\n",
      "Countdown: 422 \n",
      "\n",
      "Epoch: 84:\n",
      "Training loss  : 0.42146, Training accuracy  : 0.847\n",
      "Validation loss: 3.581, Validation accuracy: 0.519\n",
      "Countdown: 421 \n",
      "\n",
      "Epoch: 85:\n",
      "Training loss  : 0.43425, Training accuracy  : 0.842\n",
      "Validation loss: 3.836, Validation accuracy: 0.443\n",
      "Countdown: 420 \n",
      "\n",
      "Epoch: 86:\n",
      "Training loss  : 0.42789, Training accuracy  : 0.843\n",
      "Validation loss: 3.421, Validation accuracy: 0.466\n",
      "Countdown: 419 \n",
      "\n",
      "Epoch: 87:\n",
      "Training loss  : 0.39014, Training accuracy  : 0.858\n",
      "Validation loss: 3.727, Validation accuracy: 0.473\n",
      "Countdown: 418 \n",
      "\n",
      "Epoch: 88:\n",
      "Training loss  : 0.39019, Training accuracy  : 0.859\n",
      "Validation loss: 4.141, Validation accuracy: 0.490\n",
      "Countdown: 417 \n",
      "\n",
      "Epoch: 89:\n",
      "Training loss  : 0.42110, Training accuracy  : 0.849\n",
      "Validation loss: 4.113, Validation accuracy: 0.474\n",
      "Countdown: 416 \n",
      "\n",
      "Epoch: 90:\n",
      "Training loss  : 0.37940, Training accuracy  : 0.866\n",
      "Validation loss: 3.907, Validation accuracy: 0.475\n",
      "Countdown: 415 \n",
      "\n",
      "Epoch: 91:\n",
      "Training loss  : 0.36434, Training accuracy  : 0.870\n",
      "Validation loss: 4.206, Validation accuracy: 0.488\n",
      "Countdown: 414 \n",
      "\n",
      "Epoch: 92:\n",
      "Training loss  : 0.37985, Training accuracy  : 0.864\n",
      "Validation loss: 4.267, Validation accuracy: 0.436\n",
      "Countdown: 413 \n",
      "\n",
      "Epoch: 93:\n",
      "Training loss  : 0.40066, Training accuracy  : 0.858\n",
      "Validation loss: 3.344, Validation accuracy: 0.512\n",
      "Countdown: 412 \n",
      "\n",
      "Epoch: 94:\n",
      "Training loss  : 0.38206, Training accuracy  : 0.864\n",
      "Validation loss: 4.034, Validation accuracy: 0.486\n",
      "Countdown: 411 \n",
      "\n",
      "Epoch: 95:\n",
      "Training loss  : 0.37256, Training accuracy  : 0.866\n",
      "Validation loss: 4.122, Validation accuracy: 0.476\n",
      "Countdown: 410 \n",
      "\n",
      "Epoch: 96:\n",
      "Training loss  : 0.39300, Training accuracy  : 0.858\n",
      "Validation loss: 4.017, Validation accuracy: 0.492\n",
      "Countdown: 409 \n",
      "\n",
      "Epoch: 97:\n",
      "Training loss  : 0.35610, Training accuracy  : 0.871\n",
      "Validation loss: 4.181, Validation accuracy: 0.513\n",
      "Countdown: 408 \n",
      "\n",
      "Epoch: 98:\n",
      "Training loss  : 0.36977, Training accuracy  : 0.869\n",
      "Validation loss: 4.234, Validation accuracy: 0.482\n",
      "Countdown: 407 \n",
      "\n",
      "Epoch: 99:\n",
      "Training loss  : 0.35502, Training accuracy  : 0.871\n",
      "Validation loss: 4.113, Validation accuracy: 0.480\n",
      "Countdown: 406 \n",
      "\n",
      "Epoch: 100:\n",
      "Training loss  : 0.35053, Training accuracy  : 0.874\n",
      "Validation loss: 4.157, Validation accuracy: 0.497\n",
      "Countdown: 405 \n",
      "\n",
      "Epoch: 101:\n",
      "Training loss  : 0.34477, Training accuracy  : 0.880\n",
      "Validation loss: 4.382, Validation accuracy: 0.488\n",
      "Countdown: 404 \n",
      "\n",
      "Epoch: 102:\n",
      "Training loss  : 0.36175, Training accuracy  : 0.871\n",
      "Validation loss: 4.202, Validation accuracy: 0.508\n",
      "Countdown: 403 \n",
      "\n",
      "Epoch: 103:\n",
      "Training loss  : 0.39045, Training accuracy  : 0.859\n",
      "Validation loss: 4.537, Validation accuracy: 0.504\n",
      "Countdown: 402 \n",
      "\n",
      "Epoch: 104:\n",
      "Training loss  : 0.37894, Training accuracy  : 0.869\n",
      "Validation loss: 4.122, Validation accuracy: 0.527\n",
      "Countdown: 401 \n",
      "\n",
      "Epoch: 105:\n",
      "Training loss  : 0.38821, Training accuracy  : 0.863\n",
      "Validation loss: 4.207, Validation accuracy: 0.457\n",
      "Countdown: 400 \n",
      "\n",
      "Epoch: 106:\n",
      "Training loss  : 0.42461, Training accuracy  : 0.850\n",
      "Validation loss: 4.074, Validation accuracy: 0.499\n",
      "Countdown: 399 \n",
      "\n",
      "Epoch: 107:\n",
      "Training loss  : 0.37715, Training accuracy  : 0.872\n",
      "Validation loss: 4.304, Validation accuracy: 0.453\n",
      "Countdown: 398 \n",
      "\n",
      "Epoch: 108:\n",
      "Training loss  : 0.40662, Training accuracy  : 0.854\n",
      "Validation loss: 3.653, Validation accuracy: 0.499\n",
      "Countdown: 397 \n",
      "\n",
      "Epoch: 109:\n",
      "Training loss  : 0.36476, Training accuracy  : 0.867\n",
      "Validation loss: 3.501, Validation accuracy: 0.507\n",
      "Countdown: 396 \n",
      "\n",
      "Epoch: 110:\n",
      "Training loss  : 0.39341, Training accuracy  : 0.860\n",
      "Validation loss: 4.418, Validation accuracy: 0.469\n",
      "Countdown: 395 \n",
      "\n",
      "Epoch: 111:\n",
      "Training loss  : 0.49330, Training accuracy  : 0.826\n",
      "Validation loss: 3.925, Validation accuracy: 0.447\n",
      "Countdown: 394 \n",
      "\n",
      "Epoch: 112:\n",
      "Training loss  : 0.47868, Training accuracy  : 0.826\n",
      "Validation loss: 4.612, Validation accuracy: 0.441\n",
      "Countdown: 393 \n",
      "\n",
      "Epoch: 113:\n",
      "Training loss  : 0.36965, Training accuracy  : 0.870\n",
      "Validation loss: 3.466, Validation accuracy: 0.487\n",
      "Countdown: 392 \n",
      "\n",
      "Epoch: 114:\n",
      "Training loss  : 0.37884, Training accuracy  : 0.863\n",
      "Validation loss: 3.907, Validation accuracy: 0.486\n",
      "Countdown: 391 \n",
      "\n",
      "Epoch: 115:\n",
      "Training loss  : 0.37598, Training accuracy  : 0.866\n",
      "Validation loss: 4.182, Validation accuracy: 0.475\n",
      "Countdown: 390 \n",
      "\n",
      "Epoch: 116:\n",
      "Training loss  : 0.40275, Training accuracy  : 0.859\n",
      "Validation loss: 4.402, Validation accuracy: 0.452\n",
      "Countdown: 389 \n",
      "\n",
      "Epoch: 117:\n",
      "Training loss  : 0.39920, Training accuracy  : 0.853\n",
      "Validation loss: 3.905, Validation accuracy: 0.491\n",
      "Countdown: 388 \n",
      "\n",
      "Epoch: 118:\n",
      "Training loss  : 0.40867, Training accuracy  : 0.855\n",
      "Validation loss: 4.264, Validation accuracy: 0.492\n",
      "Countdown: 387 \n",
      "\n",
      "Epoch: 119:\n",
      "Training loss  : 0.44132, Training accuracy  : 0.841\n",
      "Validation loss: 4.292, Validation accuracy: 0.492\n",
      "Countdown: 386 \n",
      "\n",
      "Epoch: 120:\n",
      "Training loss  : 0.43476, Training accuracy  : 0.853\n",
      "Validation loss: 3.192, Validation accuracy: 0.523\n",
      "Countdown: 385 \n",
      "\n",
      "Epoch: 121:\n",
      "Training loss  : 0.43512, Training accuracy  : 0.849\n",
      "Validation loss: 4.048, Validation accuracy: 0.469\n",
      "Countdown: 384 \n",
      "\n",
      "Epoch: 122:\n",
      "Training loss  : 0.36103, Training accuracy  : 0.873\n",
      "Validation loss: 3.719, Validation accuracy: 0.494\n",
      "Countdown: 383 \n",
      "\n",
      "Epoch: 123:\n",
      "Training loss  : 0.36893, Training accuracy  : 0.868\n",
      "Validation loss: 3.577, Validation accuracy: 0.514\n",
      "Countdown: 382 \n",
      "\n",
      "Epoch: 124:\n",
      "Training loss  : 0.37225, Training accuracy  : 0.867\n",
      "Validation loss: 3.977, Validation accuracy: 0.473\n",
      "Countdown: 381 \n",
      "\n",
      "Epoch: 125:\n",
      "Training loss  : 0.38735, Training accuracy  : 0.860\n",
      "Validation loss: 3.972, Validation accuracy: 0.495\n",
      "Countdown: 380 \n",
      "\n",
      "Epoch: 126:\n",
      "Training loss  : 0.44060, Training accuracy  : 0.843\n",
      "Validation loss: 4.699, Validation accuracy: 0.516\n",
      "Countdown: 379 \n",
      "\n",
      "Epoch: 127:\n",
      "Training loss  : 0.41350, Training accuracy  : 0.854\n",
      "Validation loss: 3.803, Validation accuracy: 0.511\n",
      "Countdown: 378 \n",
      "\n",
      "Epoch: 128:\n",
      "Training loss  : 0.37836, Training accuracy  : 0.867\n",
      "Validation loss: 3.683, Validation accuracy: 0.522\n",
      "Countdown: 377 \n",
      "\n",
      "Epoch: 129:\n",
      "Training loss  : 0.36528, Training accuracy  : 0.871\n",
      "Validation loss: 4.311, Validation accuracy: 0.479\n",
      "Countdown: 376 \n",
      "\n",
      "Epoch: 130:\n",
      "Training loss  : 0.37250, Training accuracy  : 0.867\n",
      "Validation loss: 3.992, Validation accuracy: 0.519\n",
      "Countdown: 375 \n",
      "\n",
      "Epoch: 131:\n",
      "Training loss  : 0.41444, Training accuracy  : 0.854\n",
      "Validation loss: 4.140, Validation accuracy: 0.458\n",
      "Countdown: 374 \n",
      "\n",
      "Epoch: 132:\n",
      "Training loss  : 0.39516, Training accuracy  : 0.858\n",
      "Validation loss: 4.503, Validation accuracy: 0.455\n",
      "Countdown: 373 \n",
      "\n",
      "Epoch: 133:\n",
      "Training loss  : 0.40314, Training accuracy  : 0.858\n",
      "Validation loss: 4.485, Validation accuracy: 0.474\n",
      "Countdown: 372 \n",
      "\n",
      "Epoch: 134:\n",
      "Training loss  : 0.38492, Training accuracy  : 0.862\n",
      "Validation loss: 4.259, Validation accuracy: 0.464\n",
      "Countdown: 371 \n",
      "\n",
      "Epoch: 135:\n",
      "Training loss  : 0.40752, Training accuracy  : 0.864\n",
      "Validation loss: 4.428, Validation accuracy: 0.476\n",
      "Countdown: 370 \n",
      "\n",
      "Epoch: 136:\n",
      "Training loss  : 0.34458, Training accuracy  : 0.881\n",
      "Validation loss: 5.240, Validation accuracy: 0.445\n",
      "Countdown: 369 \n",
      "\n",
      "Epoch: 137:\n",
      "Training loss  : 0.32186, Training accuracy  : 0.890\n",
      "Validation loss: 5.122, Validation accuracy: 0.459\n",
      "Countdown: 368 \n",
      "\n",
      "Epoch: 138:\n",
      "Training loss  : 0.34701, Training accuracy  : 0.879\n",
      "Validation loss: 4.677, Validation accuracy: 0.448\n",
      "Countdown: 367 \n",
      "\n",
      "Epoch: 139:\n",
      "Training loss  : 0.32240, Training accuracy  : 0.890\n",
      "Validation loss: 5.250, Validation accuracy: 0.446\n",
      "Countdown: 366 \n",
      "\n",
      "Epoch: 140:\n",
      "Training loss  : 0.32012, Training accuracy  : 0.884\n",
      "Validation loss: 4.870, Validation accuracy: 0.477\n",
      "Countdown: 365 \n",
      "\n",
      "Epoch: 141:\n",
      "Training loss  : 0.34314, Training accuracy  : 0.882\n",
      "Validation loss: 4.991, Validation accuracy: 0.454\n",
      "Countdown: 364 \n",
      "\n",
      "Epoch: 142:\n",
      "Training loss  : 0.45195, Training accuracy  : 0.842\n",
      "Validation loss: 3.857, Validation accuracy: 0.512\n",
      "Countdown: 363 \n",
      "\n",
      "Epoch: 143:\n",
      "Training loss  : 0.35481, Training accuracy  : 0.873\n",
      "Validation loss: 4.681, Validation accuracy: 0.496\n",
      "Countdown: 362 \n",
      "\n",
      "Epoch: 144:\n",
      "Training loss  : 0.35308, Training accuracy  : 0.874\n",
      "Validation loss: 4.443, Validation accuracy: 0.475\n",
      "Countdown: 361 \n",
      "\n",
      "Epoch: 145:\n",
      "Training loss  : 0.35604, Training accuracy  : 0.876\n",
      "Validation loss: 3.901, Validation accuracy: 0.487\n",
      "Countdown: 360 \n",
      "\n",
      "Epoch: 146:\n",
      "Training loss  : 0.35898, Training accuracy  : 0.874\n",
      "Validation loss: 4.580, Validation accuracy: 0.458\n",
      "Countdown: 359 \n",
      "\n",
      "Epoch: 147:\n",
      "Training loss  : 0.37622, Training accuracy  : 0.869\n",
      "Validation loss: 4.691, Validation accuracy: 0.462\n",
      "Countdown: 358 \n",
      "\n",
      "Epoch: 148:\n",
      "Training loss  : 0.31860, Training accuracy  : 0.887\n",
      "Validation loss: 5.149, Validation accuracy: 0.504\n",
      "Countdown: 357 \n",
      "\n",
      "Epoch: 149:\n",
      "Training loss  : 0.31578, Training accuracy  : 0.889\n",
      "Validation loss: 4.473, Validation accuracy: 0.495\n",
      "Countdown: 356 \n",
      "\n",
      "Epoch: 150:\n",
      "Training loss  : 0.33271, Training accuracy  : 0.883\n",
      "Validation loss: 4.534, Validation accuracy: 0.459\n",
      "Countdown: 355 \n",
      "\n",
      "Epoch: 151:\n",
      "Training loss  : 0.31595, Training accuracy  : 0.891\n",
      "Validation loss: 5.411, Validation accuracy: 0.462\n",
      "Countdown: 354 \n",
      "\n",
      "Epoch: 152:\n",
      "Training loss  : 0.31886, Training accuracy  : 0.887\n",
      "Validation loss: 4.332, Validation accuracy: 0.475\n",
      "Countdown: 353 \n",
      "\n",
      "Epoch: 153:\n",
      "Training loss  : 0.34671, Training accuracy  : 0.880\n",
      "Validation loss: 5.059, Validation accuracy: 0.491\n",
      "Countdown: 352 \n",
      "\n",
      "Epoch: 154:\n",
      "Training loss  : 0.33475, Training accuracy  : 0.880\n",
      "Validation loss: 3.762, Validation accuracy: 0.555\n",
      "Countdown: 351 \n",
      "\n",
      "Epoch: 155:\n",
      "Training loss  : 0.34766, Training accuracy  : 0.879\n",
      "Validation loss: 3.876, Validation accuracy: 0.510\n",
      "Countdown: 350 \n",
      "\n",
      "Epoch: 156:\n",
      "Training loss  : 0.33680, Training accuracy  : 0.885\n",
      "Validation loss: 4.289, Validation accuracy: 0.542\n",
      "Countdown: 349 \n",
      "\n",
      "Epoch: 157:\n",
      "Training loss  : 0.33102, Training accuracy  : 0.880\n",
      "Validation loss: 5.258, Validation accuracy: 0.504\n",
      "Countdown: 348 \n",
      "\n",
      "Epoch: 158:\n",
      "Training loss  : 0.36540, Training accuracy  : 0.872\n",
      "Validation loss: 4.928, Validation accuracy: 0.470\n",
      "Countdown: 347 \n",
      "\n",
      "Epoch: 159:\n",
      "Training loss  : 0.32308, Training accuracy  : 0.884\n",
      "Validation loss: 4.817, Validation accuracy: 0.492\n",
      "Countdown: 346 \n",
      "\n",
      "Epoch: 160:\n",
      "Training loss  : 0.30835, Training accuracy  : 0.890\n",
      "Validation loss: 5.087, Validation accuracy: 0.468\n",
      "Countdown: 345 \n",
      "\n",
      "Epoch: 161:\n",
      "Training loss  : 0.34293, Training accuracy  : 0.880\n",
      "Validation loss: 4.627, Validation accuracy: 0.487\n",
      "Countdown: 344 \n",
      "\n",
      "Epoch: 162:\n",
      "Training loss  : 0.31353, Training accuracy  : 0.891\n",
      "Validation loss: 4.746, Validation accuracy: 0.494\n",
      "Countdown: 343 \n",
      "\n",
      "Epoch: 163:\n",
      "Training loss  : 0.32535, Training accuracy  : 0.886\n",
      "Validation loss: 4.929, Validation accuracy: 0.499\n",
      "Countdown: 342 \n",
      "\n",
      "Epoch: 164:\n",
      "Training loss  : 0.34432, Training accuracy  : 0.876\n",
      "Validation loss: 4.811, Validation accuracy: 0.500\n",
      "Countdown: 341 \n",
      "\n",
      "Epoch: 165:\n",
      "Training loss  : 0.32197, Training accuracy  : 0.885\n",
      "Validation loss: 4.651, Validation accuracy: 0.481\n",
      "Countdown: 340 \n",
      "\n",
      "Epoch: 166:\n",
      "Training loss  : 0.32644, Training accuracy  : 0.885\n",
      "Validation loss: 3.792, Validation accuracy: 0.565\n",
      "Countdown: 339 \n",
      "\n",
      "Epoch: 167:\n",
      "Training loss  : 0.42708, Training accuracy  : 0.854\n",
      "Validation loss: 5.396, Validation accuracy: 0.458\n",
      "Countdown: 338 \n",
      "\n",
      "Epoch: 168:\n",
      "Training loss  : 0.38358, Training accuracy  : 0.868\n",
      "Validation loss: 3.740, Validation accuracy: 0.488\n",
      "Countdown: 337 \n",
      "\n",
      "Epoch: 169:\n",
      "Training loss  : 0.39427, Training accuracy  : 0.863\n",
      "Validation loss: 4.298, Validation accuracy: 0.502\n",
      "Countdown: 336 \n",
      "\n",
      "Epoch: 170:\n",
      "Training loss  : 0.34206, Training accuracy  : 0.883\n",
      "Validation loss: 4.904, Validation accuracy: 0.497\n",
      "Countdown: 335 \n",
      "\n",
      "Epoch: 171:\n",
      "Training loss  : 0.37486, Training accuracy  : 0.869\n",
      "Validation loss: 4.749, Validation accuracy: 0.483\n",
      "Countdown: 334 \n",
      "\n",
      "Epoch: 172:\n",
      "Training loss  : 0.38084, Training accuracy  : 0.869\n",
      "Validation loss: 4.896, Validation accuracy: 0.497\n",
      "Countdown: 333 \n",
      "\n",
      "Epoch: 173:\n",
      "Training loss  : 0.38346, Training accuracy  : 0.859\n",
      "Validation loss: 5.632, Validation accuracy: 0.481\n",
      "Countdown: 332 \n",
      "\n",
      "Epoch: 174:\n",
      "Training loss  : 0.39543, Training accuracy  : 0.859\n",
      "Validation loss: 4.437, Validation accuracy: 0.510\n",
      "Countdown: 331 \n",
      "\n",
      "Epoch: 175:\n",
      "Training loss  : 0.36455, Training accuracy  : 0.868\n",
      "Validation loss: 5.112, Validation accuracy: 0.478\n",
      "Countdown: 330 \n",
      "\n",
      "Epoch: 176:\n",
      "Training loss  : 0.34600, Training accuracy  : 0.883\n",
      "Validation loss: 5.320, Validation accuracy: 0.503\n",
      "Countdown: 329 \n",
      "\n",
      "Epoch: 177:\n",
      "Training loss  : 0.37568, Training accuracy  : 0.866\n",
      "Validation loss: 6.003, Validation accuracy: 0.435\n",
      "Countdown: 328 \n",
      "\n",
      "Epoch: 178:\n",
      "Training loss  : 0.37625, Training accuracy  : 0.860\n",
      "Validation loss: 5.528, Validation accuracy: 0.491\n",
      "Countdown: 327 \n",
      "\n",
      "Epoch: 179:\n",
      "Training loss  : 0.36360, Training accuracy  : 0.871\n",
      "Validation loss: 4.415, Validation accuracy: 0.509\n",
      "Countdown: 326 \n",
      "\n",
      "Epoch: 180:\n",
      "Training loss  : 0.33118, Training accuracy  : 0.881\n",
      "Validation loss: 3.868, Validation accuracy: 0.517\n",
      "Countdown: 325 \n",
      "\n",
      "Epoch: 181:\n",
      "Training loss  : 0.31567, Training accuracy  : 0.887\n",
      "Validation loss: 4.986, Validation accuracy: 0.479\n",
      "Countdown: 324 \n",
      "\n",
      "Epoch: 182:\n",
      "Training loss  : 0.32751, Training accuracy  : 0.884\n",
      "Validation loss: 5.353, Validation accuracy: 0.507\n",
      "Countdown: 323 \n",
      "\n",
      "Epoch: 183:\n",
      "Training loss  : 0.32034, Training accuracy  : 0.885\n",
      "Validation loss: 5.695, Validation accuracy: 0.498\n",
      "Countdown: 322 \n",
      "\n",
      "Epoch: 184:\n",
      "Training loss  : 0.31182, Training accuracy  : 0.890\n",
      "Validation loss: 4.883, Validation accuracy: 0.504\n",
      "Countdown: 321 \n",
      "\n",
      "Epoch: 185:\n",
      "Training loss  : 0.30307, Training accuracy  : 0.894\n",
      "Validation loss: 5.474, Validation accuracy: 0.494\n",
      "Countdown: 320 \n",
      "\n",
      "Epoch: 186:\n",
      "Training loss  : 0.30659, Training accuracy  : 0.895\n",
      "Validation loss: 4.832, Validation accuracy: 0.540\n",
      "Countdown: 319 \n",
      "\n",
      "Epoch: 187:\n",
      "Training loss  : 0.34850, Training accuracy  : 0.881\n",
      "Validation loss: 5.301, Validation accuracy: 0.477\n",
      "Countdown: 318 \n",
      "\n",
      "Epoch: 188:\n",
      "Training loss  : 0.33303, Training accuracy  : 0.882\n",
      "Validation loss: 4.721, Validation accuracy: 0.512\n",
      "Countdown: 317 \n",
      "\n",
      "Epoch: 189:\n",
      "Training loss  : 0.35120, Training accuracy  : 0.881\n",
      "Validation loss: 4.345, Validation accuracy: 0.489\n",
      "Countdown: 316 \n",
      "\n",
      "Epoch: 190:\n",
      "Training loss  : 0.31999, Training accuracy  : 0.890\n",
      "Validation loss: 4.995, Validation accuracy: 0.493\n",
      "Countdown: 315 \n",
      "\n",
      "Epoch: 191:\n",
      "Training loss  : 0.33142, Training accuracy  : 0.877\n",
      "Validation loss: 4.221, Validation accuracy: 0.536\n",
      "Countdown: 314 \n",
      "\n",
      "Epoch: 192:\n",
      "Training loss  : 0.36648, Training accuracy  : 0.872\n",
      "Validation loss: 5.374, Validation accuracy: 0.519\n",
      "Countdown: 313 \n",
      "\n",
      "Epoch: 193:\n",
      "Training loss  : 0.42729, Training accuracy  : 0.853\n",
      "Validation loss: 4.512, Validation accuracy: 0.474\n",
      "Countdown: 312 \n",
      "\n",
      "Epoch: 194:\n",
      "Training loss  : 0.37150, Training accuracy  : 0.869\n",
      "Validation loss: 4.516, Validation accuracy: 0.515\n",
      "Countdown: 311 \n",
      "\n",
      "Epoch: 195:\n",
      "Training loss  : 0.37040, Training accuracy  : 0.870\n",
      "Validation loss: 5.135, Validation accuracy: 0.500\n",
      "Countdown: 310 \n",
      "\n",
      "Epoch: 196:\n",
      "Training loss  : 0.36029, Training accuracy  : 0.875\n",
      "Validation loss: 6.044, Validation accuracy: 0.430\n",
      "Countdown: 309 \n",
      "\n",
      "Epoch: 197:\n",
      "Training loss  : 0.38302, Training accuracy  : 0.865\n",
      "Validation loss: 6.346, Validation accuracy: 0.476\n",
      "Countdown: 308 \n",
      "\n",
      "Epoch: 198:\n",
      "Training loss  : 0.35778, Training accuracy  : 0.875\n",
      "Validation loss: 5.311, Validation accuracy: 0.420\n",
      "Countdown: 307 \n",
      "\n",
      "Epoch: 199:\n",
      "Training loss  : 0.33214, Training accuracy  : 0.882\n",
      "Validation loss: 4.907, Validation accuracy: 0.483\n",
      "Countdown: 306 \n",
      "\n",
      "Epoch: 200:\n",
      "Training loss  : 0.31742, Training accuracy  : 0.890\n",
      "Validation loss: 5.402, Validation accuracy: 0.479\n",
      "Countdown: 305 \n",
      "\n",
      "Epoch: 201:\n",
      "Training loss  : 0.31605, Training accuracy  : 0.884\n",
      "Validation loss: 5.348, Validation accuracy: 0.492\n",
      "Countdown: 304 \n",
      "\n",
      "Epoch: 202:\n",
      "Training loss  : 0.29834, Training accuracy  : 0.894\n",
      "Validation loss: 5.371, Validation accuracy: 0.466\n",
      "Countdown: 303 \n",
      "\n",
      "Epoch: 203:\n",
      "Training loss  : 0.28672, Training accuracy  : 0.900\n",
      "Validation loss: 5.251, Validation accuracy: 0.481\n",
      "Countdown: 302 \n",
      "\n",
      "Epoch: 204:\n",
      "Training loss  : 0.28975, Training accuracy  : 0.897\n",
      "Validation loss: 4.714, Validation accuracy: 0.522\n",
      "Countdown: 301 \n",
      "\n",
      "Epoch: 205:\n",
      "Training loss  : 0.33197, Training accuracy  : 0.881\n",
      "Validation loss: 5.381, Validation accuracy: 0.472\n",
      "Countdown: 300 \n",
      "\n",
      "Epoch: 206:\n",
      "Training loss  : 0.29269, Training accuracy  : 0.899\n",
      "Validation loss: 4.898, Validation accuracy: 0.502\n",
      "Countdown: 299 \n",
      "\n",
      "Epoch: 207:\n",
      "Training loss  : 0.34065, Training accuracy  : 0.883\n",
      "Validation loss: 4.288, Validation accuracy: 0.527\n",
      "Countdown: 298 \n",
      "\n",
      "Epoch: 208:\n",
      "Training loss  : 0.30058, Training accuracy  : 0.896\n",
      "Validation loss: 4.328, Validation accuracy: 0.542\n",
      "Countdown: 297 \n",
      "\n",
      "Epoch: 209:\n",
      "Training loss  : 0.31852, Training accuracy  : 0.893\n",
      "Validation loss: 4.330, Validation accuracy: 0.518\n",
      "Countdown: 296 \n",
      "\n",
      "Epoch: 210:\n",
      "Training loss  : 0.31577, Training accuracy  : 0.888\n",
      "Validation loss: 4.727, Validation accuracy: 0.505\n",
      "Countdown: 295 \n",
      "\n",
      "Epoch: 211:\n",
      "Training loss  : 0.30402, Training accuracy  : 0.895\n",
      "Validation loss: 5.591, Validation accuracy: 0.474\n",
      "Countdown: 294 \n",
      "\n",
      "Epoch: 212:\n",
      "Training loss  : 0.30616, Training accuracy  : 0.891\n",
      "Validation loss: 4.698, Validation accuracy: 0.509\n",
      "Countdown: 293 \n",
      "\n",
      "Epoch: 213:\n",
      "Training loss  : 0.29114, Training accuracy  : 0.898\n",
      "Validation loss: 5.899, Validation accuracy: 0.498\n",
      "Countdown: 292 \n",
      "\n",
      "Epoch: 214:\n",
      "Training loss  : 0.30744, Training accuracy  : 0.890\n",
      "Validation loss: 5.316, Validation accuracy: 0.483\n",
      "Countdown: 291 \n",
      "\n",
      "Epoch: 215:\n",
      "Training loss  : 0.29299, Training accuracy  : 0.897\n",
      "Validation loss: 5.652, Validation accuracy: 0.497\n",
      "Countdown: 290 \n",
      "\n",
      "Epoch: 216:\n",
      "Training loss  : 0.27973, Training accuracy  : 0.899\n",
      "Validation loss: 5.607, Validation accuracy: 0.518\n",
      "Countdown: 289 \n",
      "\n",
      "Epoch: 217:\n",
      "Training loss  : 0.28255, Training accuracy  : 0.900\n",
      "Validation loss: 5.814, Validation accuracy: 0.491\n",
      "Countdown: 288 \n",
      "\n",
      "Epoch: 218:\n",
      "Training loss  : 0.29368, Training accuracy  : 0.896\n",
      "Validation loss: 5.752, Validation accuracy: 0.477\n",
      "Countdown: 287 \n",
      "\n",
      "Epoch: 219:\n",
      "Training loss  : 0.35121, Training accuracy  : 0.879\n",
      "Validation loss: 4.667, Validation accuracy: 0.487\n",
      "Countdown: 286 \n",
      "\n",
      "Epoch: 220:\n",
      "Training loss  : 0.34958, Training accuracy  : 0.877\n",
      "Validation loss: 5.692, Validation accuracy: 0.463\n",
      "Countdown: 285 \n",
      "\n",
      "Epoch: 221:\n",
      "Training loss  : 0.30652, Training accuracy  : 0.891\n",
      "Validation loss: 4.422, Validation accuracy: 0.519\n",
      "Countdown: 284 \n",
      "\n",
      "Epoch: 222:\n",
      "Training loss  : 0.31693, Training accuracy  : 0.887\n",
      "Validation loss: 5.784, Validation accuracy: 0.456\n",
      "Countdown: 283 \n",
      "\n",
      "Epoch: 223:\n",
      "Training loss  : 0.36045, Training accuracy  : 0.871\n",
      "Validation loss: 5.334, Validation accuracy: 0.455\n",
      "Countdown: 282 \n",
      "\n",
      "Epoch: 224:\n",
      "Training loss  : 0.34555, Training accuracy  : 0.876\n",
      "Validation loss: 5.906, Validation accuracy: 0.451\n",
      "Countdown: 281 \n",
      "\n",
      "Epoch: 225:\n",
      "Training loss  : 0.32288, Training accuracy  : 0.886\n",
      "Validation loss: 5.592, Validation accuracy: 0.470\n",
      "Countdown: 280 \n",
      "\n",
      "Epoch: 226:\n",
      "Training loss  : 0.31601, Training accuracy  : 0.889\n",
      "Validation loss: 5.132, Validation accuracy: 0.492\n",
      "Countdown: 279 \n",
      "\n",
      "Epoch: 227:\n",
      "Training loss  : 0.36662, Training accuracy  : 0.872\n",
      "Validation loss: 4.695, Validation accuracy: 0.469\n",
      "Countdown: 278 \n",
      "\n",
      "Epoch: 228:\n",
      "Training loss  : 0.45145, Training accuracy  : 0.850\n",
      "Validation loss: 4.442, Validation accuracy: 0.492\n",
      "Countdown: 277 \n",
      "\n",
      "Epoch: 229:\n",
      "Training loss  : 0.37744, Training accuracy  : 0.869\n",
      "Validation loss: 5.010, Validation accuracy: 0.484\n",
      "Countdown: 276 \n",
      "\n",
      "Epoch: 230:\n",
      "Training loss  : 0.31438, Training accuracy  : 0.891\n",
      "Validation loss: 5.838, Validation accuracy: 0.485\n",
      "Countdown: 275 \n",
      "\n",
      "Epoch: 231:\n",
      "Training loss  : 0.32348, Training accuracy  : 0.887\n",
      "Validation loss: 4.816, Validation accuracy: 0.483\n",
      "Countdown: 274 \n",
      "\n",
      "Epoch: 232:\n",
      "Training loss  : 0.34775, Training accuracy  : 0.879\n",
      "Validation loss: 4.410, Validation accuracy: 0.520\n",
      "Countdown: 273 \n",
      "\n",
      "Epoch: 233:\n",
      "Training loss  : 0.34843, Training accuracy  : 0.874\n",
      "Validation loss: 4.214, Validation accuracy: 0.490\n",
      "Countdown: 272 \n",
      "\n",
      "Epoch: 234:\n",
      "Training loss  : 0.31492, Training accuracy  : 0.889\n",
      "Validation loss: 5.023, Validation accuracy: 0.449\n",
      "Countdown: 271 \n",
      "\n",
      "Epoch: 235:\n",
      "Training loss  : 0.31480, Training accuracy  : 0.889\n",
      "Validation loss: 5.047, Validation accuracy: 0.485\n",
      "Countdown: 270 \n",
      "\n",
      "Epoch: 236:\n",
      "Training loss  : 0.35248, Training accuracy  : 0.879\n",
      "Validation loss: 4.474, Validation accuracy: 0.536\n",
      "Countdown: 269 \n",
      "\n",
      "Epoch: 237:\n",
      "Training loss  : 0.32535, Training accuracy  : 0.888\n",
      "Validation loss: 5.140, Validation accuracy: 0.487\n",
      "Countdown: 268 \n",
      "\n",
      "Epoch: 238:\n",
      "Training loss  : 0.34803, Training accuracy  : 0.879\n",
      "Validation loss: 4.848, Validation accuracy: 0.516\n",
      "Countdown: 267 \n",
      "\n",
      "Epoch: 239:\n",
      "Training loss  : 0.40434, Training accuracy  : 0.860\n",
      "Validation loss: 5.097, Validation accuracy: 0.449\n",
      "Countdown: 266 \n",
      "\n",
      "Epoch: 240:\n",
      "Training loss  : 0.32426, Training accuracy  : 0.888\n",
      "Validation loss: 4.148, Validation accuracy: 0.541\n",
      "Countdown: 265 \n",
      "\n",
      "Epoch: 241:\n",
      "Training loss  : 0.32665, Training accuracy  : 0.886\n",
      "Validation loss: 4.128, Validation accuracy: 0.518\n",
      "Countdown: 264 \n",
      "\n",
      "Epoch: 242:\n",
      "Training loss  : 0.33473, Training accuracy  : 0.884\n",
      "Validation loss: 3.930, Validation accuracy: 0.533\n",
      "Countdown: 263 \n",
      "\n",
      "Epoch: 243:\n",
      "Training loss  : 0.31451, Training accuracy  : 0.892\n",
      "Validation loss: 4.622, Validation accuracy: 0.539\n",
      "Countdown: 262 \n",
      "\n",
      "Epoch: 244:\n",
      "Training loss  : 0.33236, Training accuracy  : 0.883\n",
      "Validation loss: 3.691, Validation accuracy: 0.547\n",
      "Countdown: 261 \n",
      "\n",
      "Epoch: 245:\n",
      "Training loss  : 0.33383, Training accuracy  : 0.881\n",
      "Validation loss: 4.965, Validation accuracy: 0.499\n",
      "Countdown: 260 \n",
      "\n",
      "Epoch: 246:\n",
      "Training loss  : 0.31523, Training accuracy  : 0.886\n",
      "Validation loss: 3.856, Validation accuracy: 0.519\n",
      "Countdown: 259 \n",
      "\n",
      "Epoch: 247:\n",
      "Training loss  : 0.30571, Training accuracy  : 0.890\n",
      "Validation loss: 4.541, Validation accuracy: 0.507\n",
      "Countdown: 258 \n",
      "\n",
      "Epoch: 248:\n",
      "Training loss  : 0.31828, Training accuracy  : 0.889\n",
      "Validation loss: 4.892, Validation accuracy: 0.537\n",
      "Countdown: 257 \n",
      "\n",
      "Epoch: 249:\n",
      "Training loss  : 0.28153, Training accuracy  : 0.902\n",
      "Validation loss: 4.767, Validation accuracy: 0.525\n",
      "Countdown: 256 \n",
      "\n",
      "Epoch: 250:\n",
      "Training loss  : 0.28329, Training accuracy  : 0.901\n",
      "Validation loss: 5.567, Validation accuracy: 0.521\n",
      "Countdown: 255 \n",
      "\n",
      "Epoch: 251:\n",
      "Training loss  : 0.26222, Training accuracy  : 0.909\n",
      "Validation loss: 5.555, Validation accuracy: 0.520\n",
      "Countdown: 254 \n",
      "\n",
      "Epoch: 252:\n",
      "Training loss  : 0.24880, Training accuracy  : 0.913\n",
      "Validation loss: 5.469, Validation accuracy: 0.533\n",
      "Countdown: 253 \n",
      "\n",
      "Epoch: 253:\n",
      "Training loss  : 0.31707, Training accuracy  : 0.887\n",
      "Validation loss: 5.464, Validation accuracy: 0.536\n",
      "Countdown: 252 \n",
      "\n",
      "Epoch: 254:\n",
      "Training loss  : 0.51672, Training accuracy  : 0.840\n",
      "Validation loss: 4.562, Validation accuracy: 0.488\n",
      "Countdown: 251 \n",
      "\n",
      "Epoch: 255:\n",
      "Training loss  : 0.29080, Training accuracy  : 0.902\n",
      "Validation loss: 4.755, Validation accuracy: 0.524\n",
      "Countdown: 250 \n",
      "\n",
      "Epoch: 256:\n",
      "Training loss  : 0.27360, Training accuracy  : 0.905\n",
      "Validation loss: 5.801, Validation accuracy: 0.452\n",
      "Countdown: 249 \n",
      "\n",
      "Epoch: 257:\n",
      "Training loss  : 0.27032, Training accuracy  : 0.906\n",
      "Validation loss: 5.346, Validation accuracy: 0.511\n",
      "Countdown: 248 \n",
      "\n",
      "Epoch: 258:\n",
      "Training loss  : 0.27588, Training accuracy  : 0.902\n",
      "Validation loss: 4.889, Validation accuracy: 0.519\n",
      "Countdown: 247 \n",
      "\n",
      "Epoch: 259:\n",
      "Training loss  : 0.25622, Training accuracy  : 0.910\n",
      "Validation loss: 4.870, Validation accuracy: 0.501\n",
      "Countdown: 246 \n",
      "\n",
      "Epoch: 260:\n",
      "Training loss  : 0.27201, Training accuracy  : 0.902\n",
      "Validation loss: 4.878, Validation accuracy: 0.526\n",
      "Countdown: 245 \n",
      "\n",
      "Epoch: 261:\n",
      "Training loss  : 0.26955, Training accuracy  : 0.903\n",
      "Validation loss: 4.731, Validation accuracy: 0.508\n",
      "Countdown: 244 \n",
      "\n",
      "Epoch: 262:\n",
      "Training loss  : 0.26139, Training accuracy  : 0.905\n",
      "Validation loss: 6.231, Validation accuracy: 0.467\n",
      "Countdown: 243 \n",
      "\n",
      "Epoch: 263:\n",
      "Training loss  : 0.24497, Training accuracy  : 0.912\n",
      "Validation loss: 4.522, Validation accuracy: 0.524\n",
      "Countdown: 242 \n",
      "\n",
      "Epoch: 264:\n",
      "Training loss  : 0.28490, Training accuracy  : 0.899\n",
      "Validation loss: 5.688, Validation accuracy: 0.521\n",
      "Countdown: 241 \n",
      "\n",
      "Epoch: 265:\n",
      "Training loss  : 0.26601, Training accuracy  : 0.905\n",
      "Validation loss: 5.055, Validation accuracy: 0.501\n",
      "Countdown: 240 \n",
      "\n",
      "Epoch: 266:\n",
      "Training loss  : 0.24630, Training accuracy  : 0.914\n",
      "Validation loss: 5.379, Validation accuracy: 0.501\n",
      "Countdown: 239 \n",
      "\n",
      "Epoch: 267:\n",
      "Training loss  : 0.25743, Training accuracy  : 0.911\n",
      "Validation loss: 5.557, Validation accuracy: 0.473\n",
      "Countdown: 238 \n",
      "\n",
      "Epoch: 268:\n",
      "Training loss  : 0.31424, Training accuracy  : 0.889\n",
      "Validation loss: 4.569, Validation accuracy: 0.570\n",
      "Countdown: 237 \n",
      "\n",
      "Epoch: 269:\n",
      "Training loss  : 0.43117, Training accuracy  : 0.855\n",
      "Validation loss: 4.713, Validation accuracy: 0.498\n",
      "Countdown: 236 \n",
      "\n",
      "Epoch: 270:\n",
      "Training loss  : 0.32295, Training accuracy  : 0.886\n",
      "Validation loss: 5.072, Validation accuracy: 0.480\n",
      "Countdown: 235 \n",
      "\n",
      "Epoch: 271:\n",
      "Training loss  : 0.26080, Training accuracy  : 0.910\n",
      "Validation loss: 5.336, Validation accuracy: 0.468\n",
      "Countdown: 234 \n",
      "\n",
      "Epoch: 272:\n",
      "Training loss  : 0.23067, Training accuracy  : 0.920\n",
      "Validation loss: 4.514, Validation accuracy: 0.508\n",
      "Countdown: 233 \n",
      "\n",
      "Epoch: 273:\n",
      "Training loss  : 0.26165, Training accuracy  : 0.908\n",
      "Validation loss: 6.171, Validation accuracy: 0.458\n",
      "Countdown: 232 \n",
      "\n",
      "Epoch: 274:\n",
      "Training loss  : 0.28516, Training accuracy  : 0.906\n",
      "Validation loss: 6.992, Validation accuracy: 0.497\n",
      "Countdown: 231 \n",
      "\n",
      "Epoch: 275:\n",
      "Training loss  : 0.28057, Training accuracy  : 0.901\n",
      "Validation loss: 5.103, Validation accuracy: 0.516\n",
      "Countdown: 230 \n",
      "\n",
      "Epoch: 276:\n",
      "Training loss  : 0.29348, Training accuracy  : 0.896\n",
      "Validation loss: 5.209, Validation accuracy: 0.458\n",
      "Countdown: 229 \n",
      "\n",
      "Epoch: 277:\n",
      "Training loss  : 0.26802, Training accuracy  : 0.904\n",
      "Validation loss: 5.203, Validation accuracy: 0.496\n",
      "Countdown: 228 \n",
      "\n",
      "Epoch: 278:\n",
      "Training loss  : 0.29561, Training accuracy  : 0.892\n",
      "Validation loss: 6.253, Validation accuracy: 0.486\n",
      "Countdown: 227 \n",
      "\n",
      "Epoch: 279:\n",
      "Training loss  : 0.32436, Training accuracy  : 0.886\n",
      "Validation loss: 6.492, Validation accuracy: 0.455\n",
      "Countdown: 226 \n",
      "\n",
      "Epoch: 280:\n",
      "Training loss  : 0.34770, Training accuracy  : 0.877\n",
      "Validation loss: 5.241, Validation accuracy: 0.509\n",
      "Countdown: 225 \n",
      "\n",
      "Epoch: 281:\n",
      "Training loss  : 0.31008, Training accuracy  : 0.893\n",
      "Validation loss: 4.502, Validation accuracy: 0.538\n",
      "Countdown: 224 \n",
      "\n",
      "Epoch: 282:\n",
      "Training loss  : 0.27675, Training accuracy  : 0.905\n",
      "Validation loss: 5.092, Validation accuracy: 0.489\n",
      "Countdown: 223 \n",
      "\n",
      "Epoch: 283:\n",
      "Training loss  : 0.25832, Training accuracy  : 0.906\n",
      "Validation loss: 4.789, Validation accuracy: 0.513\n",
      "Countdown: 222 \n",
      "\n",
      "Epoch: 284:\n",
      "Training loss  : 0.25468, Training accuracy  : 0.912\n",
      "Validation loss: 4.501, Validation accuracy: 0.515\n",
      "Countdown: 221 \n",
      "\n",
      "Epoch: 285:\n",
      "Training loss  : 0.37581, Training accuracy  : 0.872\n",
      "Validation loss: 4.632, Validation accuracy: 0.511\n",
      "Countdown: 220 \n",
      "\n",
      "Epoch: 286:\n",
      "Training loss  : 0.27174, Training accuracy  : 0.907\n",
      "Validation loss: 5.794, Validation accuracy: 0.490\n",
      "Countdown: 219 \n",
      "\n",
      "Epoch: 287:\n",
      "Training loss  : 0.24285, Training accuracy  : 0.914\n",
      "Validation loss: 5.397, Validation accuracy: 0.501\n",
      "Countdown: 218 \n",
      "\n",
      "Epoch: 288:\n",
      "Training loss  : 0.23305, Training accuracy  : 0.916\n",
      "Validation loss: 5.714, Validation accuracy: 0.499\n",
      "Countdown: 217 \n",
      "\n",
      "Epoch: 289:\n",
      "Training loss  : 0.25210, Training accuracy  : 0.907\n",
      "Validation loss: 4.983, Validation accuracy: 0.506\n",
      "Countdown: 216 \n",
      "\n",
      "Epoch: 290:\n",
      "Training loss  : 0.26600, Training accuracy  : 0.907\n",
      "Validation loss: 5.753, Validation accuracy: 0.482\n",
      "Countdown: 215 \n",
      "\n",
      "Epoch: 291:\n",
      "Training loss  : 0.26362, Training accuracy  : 0.903\n",
      "Validation loss: 5.601, Validation accuracy: 0.497\n",
      "Countdown: 214 \n",
      "\n",
      "Epoch: 292:\n",
      "Training loss  : 0.34305, Training accuracy  : 0.883\n",
      "Validation loss: 5.962, Validation accuracy: 0.468\n",
      "Countdown: 213 \n",
      "\n",
      "Epoch: 293:\n",
      "Training loss  : 0.31560, Training accuracy  : 0.889\n",
      "Validation loss: 5.335, Validation accuracy: 0.480\n",
      "Countdown: 212 \n",
      "\n",
      "Epoch: 294:\n",
      "Training loss  : 0.30479, Training accuracy  : 0.891\n",
      "Validation loss: 6.131, Validation accuracy: 0.465\n",
      "Countdown: 211 \n",
      "\n",
      "Epoch: 295:\n",
      "Training loss  : 0.27901, Training accuracy  : 0.907\n",
      "Validation loss: 7.742, Validation accuracy: 0.397\n",
      "Countdown: 210 \n",
      "\n",
      "Epoch: 296:\n",
      "Training loss  : 0.33114, Training accuracy  : 0.886\n",
      "Validation loss: 7.558, Validation accuracy: 0.458\n",
      "Countdown: 209 \n",
      "\n",
      "Epoch: 297:\n",
      "Training loss  : 0.29192, Training accuracy  : 0.900\n",
      "Validation loss: 6.205, Validation accuracy: 0.482\n",
      "Countdown: 208 \n",
      "\n",
      "Epoch: 298:\n",
      "Training loss  : 0.26850, Training accuracy  : 0.907\n",
      "Validation loss: 5.889, Validation accuracy: 0.503\n",
      "Countdown: 207 \n",
      "\n",
      "Epoch: 299:\n",
      "Training loss  : 0.28107, Training accuracy  : 0.904\n",
      "Validation loss: 6.284, Validation accuracy: 0.489\n",
      "Countdown: 206 \n",
      "\n",
      "Epoch: 300:\n",
      "Training loss  : 0.27638, Training accuracy  : 0.904\n",
      "Validation loss: 6.604, Validation accuracy: 0.478\n",
      "Countdown: 205 \n",
      "\n",
      "Epoch: 301:\n",
      "Training loss  : 0.26556, Training accuracy  : 0.906\n",
      "Validation loss: 6.986, Validation accuracy: 0.472\n",
      "Countdown: 204 \n",
      "\n",
      "Epoch: 302:\n",
      "Training loss  : 0.25663, Training accuracy  : 0.908\n",
      "Validation loss: 6.793, Validation accuracy: 0.442\n",
      "Countdown: 203 \n",
      "\n",
      "Epoch: 303:\n",
      "Training loss  : 0.33197, Training accuracy  : 0.887\n",
      "Validation loss: 6.607, Validation accuracy: 0.446\n",
      "Countdown: 202 \n",
      "\n",
      "Epoch: 304:\n",
      "Training loss  : 0.30189, Training accuracy  : 0.896\n",
      "Validation loss: 6.110, Validation accuracy: 0.491\n",
      "Countdown: 201 \n",
      "\n",
      "Epoch: 305:\n",
      "Training loss  : 0.28433, Training accuracy  : 0.898\n",
      "Validation loss: 6.560, Validation accuracy: 0.459\n",
      "Countdown: 200 \n",
      "\n",
      "Epoch: 306:\n",
      "Training loss  : 0.27456, Training accuracy  : 0.903\n",
      "Validation loss: 6.068, Validation accuracy: 0.478\n",
      "Countdown: 199 \n",
      "\n",
      "Epoch: 307:\n",
      "Training loss  : 0.28864, Training accuracy  : 0.894\n",
      "Validation loss: 5.956, Validation accuracy: 0.481\n",
      "Countdown: 198 \n",
      "\n",
      "Epoch: 308:\n",
      "Training loss  : 0.29492, Training accuracy  : 0.896\n",
      "Validation loss: 5.940, Validation accuracy: 0.488\n",
      "Countdown: 197 \n",
      "\n",
      "Epoch: 309:\n",
      "Training loss  : 0.28962, Training accuracy  : 0.898\n",
      "Validation loss: 7.096, Validation accuracy: 0.454\n",
      "Countdown: 196 \n",
      "\n",
      "Epoch: 310:\n",
      "Training loss  : 0.33956, Training accuracy  : 0.887\n",
      "Validation loss: 6.464, Validation accuracy: 0.415\n",
      "Countdown: 195 \n",
      "\n",
      "Epoch: 311:\n",
      "Training loss  : 0.30834, Training accuracy  : 0.896\n",
      "Validation loss: 7.061, Validation accuracy: 0.469\n",
      "Countdown: 194 \n",
      "\n",
      "Epoch: 312:\n",
      "Training loss  : 0.28974, Training accuracy  : 0.903\n",
      "Validation loss: 6.488, Validation accuracy: 0.463\n",
      "Countdown: 193 \n",
      "\n",
      "Epoch: 313:\n",
      "Training loss  : 0.32645, Training accuracy  : 0.884\n",
      "Validation loss: 5.901, Validation accuracy: 0.482\n",
      "Countdown: 192 \n",
      "\n",
      "Epoch: 314:\n",
      "Training loss  : 0.33693, Training accuracy  : 0.879\n",
      "Validation loss: 5.220, Validation accuracy: 0.480\n",
      "Countdown: 191 \n",
      "\n",
      "Epoch: 315:\n",
      "Training loss  : 0.35703, Training accuracy  : 0.877\n",
      "Validation loss: 6.036, Validation accuracy: 0.464\n",
      "Countdown: 190 \n",
      "\n",
      "Epoch: 316:\n",
      "Training loss  : 0.40023, Training accuracy  : 0.862\n",
      "Validation loss: 6.562, Validation accuracy: 0.453\n",
      "Countdown: 189 \n",
      "\n",
      "Epoch: 317:\n",
      "Training loss  : 0.29605, Training accuracy  : 0.896\n",
      "Validation loss: 6.060, Validation accuracy: 0.456\n",
      "Countdown: 188 \n",
      "\n",
      "Epoch: 318:\n",
      "Training loss  : 0.28228, Training accuracy  : 0.901\n",
      "Validation loss: 6.717, Validation accuracy: 0.471\n",
      "Countdown: 187 \n",
      "\n",
      "Epoch: 319:\n",
      "Training loss  : 0.26431, Training accuracy  : 0.907\n",
      "Validation loss: 5.570, Validation accuracy: 0.483\n",
      "Countdown: 186 \n",
      "\n",
      "Epoch: 320:\n",
      "Training loss  : 0.26072, Training accuracy  : 0.907\n",
      "Validation loss: 5.418, Validation accuracy: 0.490\n",
      "Countdown: 185 \n",
      "\n",
      "Epoch: 321:\n",
      "Training loss  : 0.25481, Training accuracy  : 0.912\n",
      "Validation loss: 5.729, Validation accuracy: 0.448\n",
      "Countdown: 184 \n",
      "\n",
      "Epoch: 322:\n",
      "Training loss  : 0.26221, Training accuracy  : 0.911\n",
      "Validation loss: 6.201, Validation accuracy: 0.410\n",
      "Countdown: 183 \n",
      "\n",
      "Epoch: 323:\n",
      "Training loss  : 0.25647, Training accuracy  : 0.911\n",
      "Validation loss: 5.412, Validation accuracy: 0.474\n",
      "Countdown: 182 \n",
      "\n",
      "Epoch: 324:\n",
      "Training loss  : 0.25800, Training accuracy  : 0.909\n",
      "Validation loss: 6.433, Validation accuracy: 0.501\n",
      "Countdown: 181 \n",
      "\n",
      "Epoch: 325:\n",
      "Training loss  : 0.27399, Training accuracy  : 0.906\n",
      "Validation loss: 6.133, Validation accuracy: 0.474\n",
      "Countdown: 180 \n",
      "\n",
      "Epoch: 326:\n",
      "Training loss  : 0.26462, Training accuracy  : 0.907\n",
      "Validation loss: 6.224, Validation accuracy: 0.477\n",
      "Countdown: 179 \n",
      "\n",
      "Epoch: 327:\n",
      "Training loss  : 0.26108, Training accuracy  : 0.912\n",
      "Validation loss: 6.313, Validation accuracy: 0.487\n",
      "Countdown: 178 \n",
      "\n",
      "Epoch: 328:\n",
      "Training loss  : 0.26182, Training accuracy  : 0.911\n",
      "Validation loss: 6.249, Validation accuracy: 0.487\n",
      "Countdown: 177 \n",
      "\n",
      "Epoch: 329:\n",
      "Training loss  : 0.24809, Training accuracy  : 0.914\n",
      "Validation loss: 7.638, Validation accuracy: 0.470\n",
      "Countdown: 176 \n",
      "\n",
      "Epoch: 330:\n",
      "Training loss  : 0.26839, Training accuracy  : 0.906\n",
      "Validation loss: 5.667, Validation accuracy: 0.471\n",
      "Countdown: 175 \n",
      "\n",
      "Epoch: 331:\n",
      "Training loss  : 0.23238, Training accuracy  : 0.918\n",
      "Validation loss: 4.116, Validation accuracy: 0.518\n",
      "Countdown: 174 \n",
      "\n",
      "Epoch: 332:\n",
      "Training loss  : 0.25166, Training accuracy  : 0.917\n",
      "Validation loss: 4.271, Validation accuracy: 0.507\n",
      "Countdown: 173 \n",
      "\n",
      "Epoch: 333:\n",
      "Training loss  : 0.23961, Training accuracy  : 0.914\n",
      "Validation loss: 5.327, Validation accuracy: 0.498\n",
      "Countdown: 172 \n",
      "\n",
      "Epoch: 334:\n",
      "Training loss  : 0.30266, Training accuracy  : 0.897\n",
      "Validation loss: 5.092, Validation accuracy: 0.456\n",
      "Countdown: 171 \n",
      "\n",
      "Epoch: 335:\n",
      "Training loss  : 0.34077, Training accuracy  : 0.883\n",
      "Validation loss: 5.709, Validation accuracy: 0.496\n",
      "Countdown: 170 \n",
      "\n",
      "Epoch: 336:\n",
      "Training loss  : 0.26999, Training accuracy  : 0.909\n",
      "Validation loss: 5.404, Validation accuracy: 0.466\n",
      "Countdown: 169 \n",
      "\n",
      "Epoch: 337:\n",
      "Training loss  : 0.27891, Training accuracy  : 0.901\n",
      "Validation loss: 5.223, Validation accuracy: 0.509\n",
      "Countdown: 168 \n",
      "\n",
      "Epoch: 338:\n",
      "Training loss  : 0.30350, Training accuracy  : 0.892\n",
      "Validation loss: 7.509, Validation accuracy: 0.486\n",
      "Countdown: 167 \n",
      "\n",
      "Epoch: 339:\n",
      "Training loss  : 0.29249, Training accuracy  : 0.896\n",
      "Validation loss: 7.019, Validation accuracy: 0.466\n",
      "Countdown: 166 \n",
      "\n",
      "Epoch: 340:\n",
      "Training loss  : 0.30057, Training accuracy  : 0.895\n",
      "Validation loss: 6.225, Validation accuracy: 0.503\n",
      "Countdown: 165 \n",
      "\n",
      "Epoch: 341:\n",
      "Training loss  : 0.33789, Training accuracy  : 0.884\n",
      "Validation loss: 5.280, Validation accuracy: 0.470\n",
      "Countdown: 164 \n",
      "\n",
      "Epoch: 342:\n",
      "Training loss  : 0.26841, Training accuracy  : 0.906\n",
      "Validation loss: 5.541, Validation accuracy: 0.487\n",
      "Countdown: 163 \n",
      "\n",
      "Epoch: 343:\n",
      "Training loss  : 0.26135, Training accuracy  : 0.908\n",
      "Validation loss: 4.147, Validation accuracy: 0.524\n",
      "Countdown: 162 \n",
      "\n",
      "Epoch: 344:\n",
      "Training loss  : 0.28717, Training accuracy  : 0.897\n",
      "Validation loss: 5.230, Validation accuracy: 0.503\n",
      "Countdown: 161 \n",
      "\n",
      "Epoch: 345:\n",
      "Training loss  : 0.33665, Training accuracy  : 0.888\n",
      "Validation loss: 5.946, Validation accuracy: 0.493\n",
      "Countdown: 160 \n",
      "\n",
      "Epoch: 346:\n",
      "Training loss  : 0.25930, Training accuracy  : 0.911\n",
      "Validation loss: 5.093, Validation accuracy: 0.502\n",
      "Countdown: 159 \n",
      "\n",
      "Epoch: 347:\n",
      "Training loss  : 0.28785, Training accuracy  : 0.896\n",
      "Validation loss: 5.415, Validation accuracy: 0.502\n",
      "Countdown: 158 \n",
      "\n",
      "Epoch: 348:\n",
      "Training loss  : 0.25391, Training accuracy  : 0.911\n",
      "Validation loss: 4.731, Validation accuracy: 0.532\n",
      "Countdown: 157 \n",
      "\n",
      "Epoch: 349:\n",
      "Training loss  : 0.26646, Training accuracy  : 0.907\n",
      "Validation loss: 6.243, Validation accuracy: 0.486\n",
      "Countdown: 156 \n",
      "\n",
      "Epoch: 350:\n",
      "Training loss  : 0.26864, Training accuracy  : 0.906\n",
      "Validation loss: 5.867, Validation accuracy: 0.524\n",
      "Countdown: 155 \n",
      "\n",
      "Epoch: 351:\n",
      "Training loss  : 0.26230, Training accuracy  : 0.910\n",
      "Validation loss: 4.858, Validation accuracy: 0.527\n",
      "Countdown: 154 \n",
      "\n",
      "Epoch: 352:\n",
      "Training loss  : 0.32507, Training accuracy  : 0.888\n",
      "Validation loss: 4.902, Validation accuracy: 0.489\n",
      "Countdown: 153 \n",
      "\n",
      "Epoch: 353:\n",
      "Training loss  : 0.33725, Training accuracy  : 0.888\n",
      "Validation loss: 4.084, Validation accuracy: 0.501\n",
      "Countdown: 152 \n",
      "\n",
      "Epoch: 354:\n",
      "Training loss  : 0.31845, Training accuracy  : 0.888\n",
      "Validation loss: 4.380, Validation accuracy: 0.526\n",
      "Countdown: 151 \n",
      "\n",
      "Epoch: 355:\n",
      "Training loss  : 0.30266, Training accuracy  : 0.894\n",
      "Validation loss: 4.012, Validation accuracy: 0.543\n",
      "Countdown: 150 \n",
      "\n",
      "Epoch: 356:\n",
      "Training loss  : 0.31496, Training accuracy  : 0.892\n",
      "Validation loss: 3.791, Validation accuracy: 0.566\n",
      "Countdown: 149 \n",
      "\n",
      "Epoch: 357:\n",
      "Training loss  : 0.33850, Training accuracy  : 0.884\n",
      "Validation loss: 2.931, Validation accuracy: 0.598\n",
      "Countdown: 148 \n",
      "\n",
      "Epoch: 358:\n",
      "Training loss  : 0.33162, Training accuracy  : 0.884\n",
      "Validation loss: 3.775, Validation accuracy: 0.565\n",
      "Countdown: 147 \n",
      "\n",
      "Epoch: 359:\n",
      "Training loss  : 0.31485, Training accuracy  : 0.891\n",
      "Validation loss: 5.220, Validation accuracy: 0.503\n",
      "Countdown: 146 \n",
      "\n",
      "Epoch: 360:\n",
      "Training loss  : 0.31315, Training accuracy  : 0.893\n",
      "Validation loss: 4.854, Validation accuracy: 0.504\n",
      "Countdown: 145 \n",
      "\n",
      "Epoch: 361:\n",
      "Training loss  : 0.29350, Training accuracy  : 0.896\n",
      "Validation loss: 4.960, Validation accuracy: 0.500\n",
      "Countdown: 144 \n",
      "\n",
      "Epoch: 362:\n",
      "Training loss  : 0.28873, Training accuracy  : 0.899\n",
      "Validation loss: 5.420, Validation accuracy: 0.508\n",
      "Countdown: 143 \n",
      "\n",
      "Epoch: 363:\n",
      "Training loss  : 0.32212, Training accuracy  : 0.891\n",
      "Validation loss: 4.195, Validation accuracy: 0.497\n",
      "Countdown: 142 \n",
      "\n",
      "Epoch: 364:\n",
      "Training loss  : 0.34456, Training accuracy  : 0.878\n",
      "Validation loss: 4.181, Validation accuracy: 0.537\n",
      "Countdown: 141 \n",
      "\n",
      "Epoch: 365:\n",
      "Training loss  : 0.28009, Training accuracy  : 0.899\n",
      "Validation loss: 5.216, Validation accuracy: 0.506\n",
      "Countdown: 140 \n",
      "\n",
      "Epoch: 366:\n",
      "Training loss  : 0.30105, Training accuracy  : 0.899\n",
      "Validation loss: 4.674, Validation accuracy: 0.496\n",
      "Countdown: 139 \n",
      "\n",
      "Epoch: 367:\n",
      "Training loss  : 0.29071, Training accuracy  : 0.893\n",
      "Validation loss: 5.705, Validation accuracy: 0.499\n",
      "Countdown: 138 \n",
      "\n",
      "Epoch: 368:\n",
      "Training loss  : 0.28312, Training accuracy  : 0.902\n",
      "Validation loss: 4.807, Validation accuracy: 0.530\n",
      "Countdown: 137 \n",
      "\n",
      "Epoch: 369:\n",
      "Training loss  : 0.34299, Training accuracy  : 0.879\n",
      "Validation loss: 5.455, Validation accuracy: 0.484\n",
      "Countdown: 136 \n",
      "\n",
      "Epoch: 370:\n",
      "Training loss  : 0.30530, Training accuracy  : 0.891\n",
      "Validation loss: 3.755, Validation accuracy: 0.547\n",
      "Countdown: 135 \n",
      "\n",
      "Epoch: 371:\n",
      "Training loss  : 0.28951, Training accuracy  : 0.903\n",
      "Validation loss: 4.427, Validation accuracy: 0.512\n",
      "Countdown: 134 \n",
      "\n",
      "Epoch: 372:\n",
      "Training loss  : 0.29263, Training accuracy  : 0.896\n",
      "Validation loss: 4.442, Validation accuracy: 0.546\n",
      "Countdown: 133 \n",
      "\n",
      "Epoch: 373:\n",
      "Training loss  : 0.28500, Training accuracy  : 0.899\n",
      "Validation loss: 3.941, Validation accuracy: 0.531\n",
      "Countdown: 132 \n",
      "\n",
      "Epoch: 374:\n",
      "Training loss  : 0.30262, Training accuracy  : 0.893\n",
      "Validation loss: 4.261, Validation accuracy: 0.523\n",
      "Countdown: 131 \n",
      "\n",
      "Epoch: 375:\n",
      "Training loss  : 0.33212, Training accuracy  : 0.886\n",
      "Validation loss: 5.090, Validation accuracy: 0.494\n",
      "Countdown: 130 \n",
      "\n",
      "Epoch: 376:\n",
      "Training loss  : 0.28378, Training accuracy  : 0.901\n",
      "Validation loss: 4.005, Validation accuracy: 0.540\n",
      "Countdown: 129 \n",
      "\n",
      "Epoch: 377:\n",
      "Training loss  : 0.26459, Training accuracy  : 0.907\n",
      "Validation loss: 4.679, Validation accuracy: 0.548\n",
      "Countdown: 128 \n",
      "\n",
      "Epoch: 378:\n",
      "Training loss  : 0.30835, Training accuracy  : 0.889\n",
      "Validation loss: 4.768, Validation accuracy: 0.513\n",
      "Countdown: 127 \n",
      "\n",
      "Epoch: 379:\n",
      "Training loss  : 0.34180, Training accuracy  : 0.889\n",
      "Validation loss: 5.789, Validation accuracy: 0.461\n",
      "Countdown: 126 \n",
      "\n",
      "Epoch: 380:\n",
      "Training loss  : 0.30802, Training accuracy  : 0.897\n",
      "Validation loss: 4.892, Validation accuracy: 0.459\n",
      "Countdown: 125 \n",
      "\n",
      "Epoch: 381:\n",
      "Training loss  : 0.27151, Training accuracy  : 0.902\n",
      "Validation loss: 5.706, Validation accuracy: 0.465\n",
      "Countdown: 124 \n",
      "\n",
      "Epoch: 382:\n",
      "Training loss  : 0.30699, Training accuracy  : 0.895\n",
      "Validation loss: 4.498, Validation accuracy: 0.521\n",
      "Countdown: 123 \n",
      "\n",
      "Epoch: 383:\n",
      "Training loss  : 0.32763, Training accuracy  : 0.885\n",
      "Validation loss: 3.950, Validation accuracy: 0.565\n",
      "Countdown: 122 \n",
      "\n",
      "Epoch: 384:\n",
      "Training loss  : 0.31230, Training accuracy  : 0.890\n",
      "Validation loss: 4.841, Validation accuracy: 0.509\n",
      "Countdown: 121 \n",
      "\n",
      "Epoch: 385:\n",
      "Training loss  : 0.28486, Training accuracy  : 0.902\n",
      "Validation loss: 6.254, Validation accuracy: 0.460\n",
      "Countdown: 120 \n",
      "\n",
      "Epoch: 386:\n",
      "Training loss  : 0.26655, Training accuracy  : 0.909\n",
      "Validation loss: 4.828, Validation accuracy: 0.515\n",
      "Countdown: 119 \n",
      "\n",
      "Epoch: 387:\n",
      "Training loss  : 0.26065, Training accuracy  : 0.907\n",
      "Validation loss: 5.595, Validation accuracy: 0.504\n",
      "Countdown: 118 \n",
      "\n",
      "Epoch: 388:\n",
      "Training loss  : 0.27662, Training accuracy  : 0.903\n",
      "Validation loss: 4.948, Validation accuracy: 0.492\n",
      "Countdown: 117 \n",
      "\n",
      "Epoch: 389:\n",
      "Training loss  : 0.25993, Training accuracy  : 0.909\n",
      "Validation loss: 5.351, Validation accuracy: 0.497\n",
      "Countdown: 116 \n",
      "\n",
      "Epoch: 390:\n",
      "Training loss  : 0.24981, Training accuracy  : 0.911\n",
      "Validation loss: 5.396, Validation accuracy: 0.465\n",
      "Countdown: 115 \n",
      "\n",
      "Epoch: 391:\n",
      "Training loss  : 0.24610, Training accuracy  : 0.914\n",
      "Validation loss: 5.197, Validation accuracy: 0.504\n",
      "Countdown: 114 \n",
      "\n",
      "Epoch: 392:\n",
      "Training loss  : 0.26824, Training accuracy  : 0.907\n",
      "Validation loss: 4.812, Validation accuracy: 0.526\n",
      "Countdown: 113 \n",
      "\n",
      "Epoch: 393:\n",
      "Training loss  : 0.24231, Training accuracy  : 0.912\n",
      "Validation loss: 6.160, Validation accuracy: 0.496\n",
      "Countdown: 112 \n",
      "\n",
      "Epoch: 394:\n",
      "Training loss  : 0.23735, Training accuracy  : 0.916\n",
      "Validation loss: 5.295, Validation accuracy: 0.467\n",
      "Countdown: 111 \n",
      "\n",
      "Epoch: 395:\n",
      "Training loss  : 0.47951, Training accuracy  : 0.845\n",
      "Validation loss: 4.081, Validation accuracy: 0.518\n",
      "Countdown: 110 \n",
      "\n",
      "Epoch: 396:\n",
      "Training loss  : 0.29511, Training accuracy  : 0.897\n",
      "Validation loss: 5.001, Validation accuracy: 0.442\n",
      "Countdown: 109 \n",
      "\n",
      "Epoch: 397:\n",
      "Training loss  : 0.28442, Training accuracy  : 0.903\n",
      "Validation loss: 5.648, Validation accuracy: 0.500\n",
      "Countdown: 108 \n",
      "\n",
      "Epoch: 398:\n",
      "Training loss  : 0.26852, Training accuracy  : 0.908\n",
      "Validation loss: 5.415, Validation accuracy: 0.441\n",
      "Countdown: 107 \n",
      "\n",
      "Epoch: 399:\n",
      "Training loss  : 0.27431, Training accuracy  : 0.905\n",
      "Validation loss: 5.282, Validation accuracy: 0.483\n",
      "Countdown: 106 \n",
      "\n",
      "Epoch: 400:\n",
      "Training loss  : 0.25733, Training accuracy  : 0.911\n",
      "Validation loss: 5.103, Validation accuracy: 0.501\n",
      "Countdown: 105 \n",
      "\n",
      "Epoch: 401:\n",
      "Training loss  : 0.24218, Training accuracy  : 0.916\n",
      "Validation loss: 5.209, Validation accuracy: 0.482\n",
      "Countdown: 104 \n",
      "\n",
      "Epoch: 402:\n",
      "Training loss  : 0.27031, Training accuracy  : 0.902\n",
      "Validation loss: 4.837, Validation accuracy: 0.522\n",
      "Countdown: 103 \n",
      "\n",
      "Epoch: 403:\n",
      "Training loss  : 0.28664, Training accuracy  : 0.903\n",
      "Validation loss: 6.387, Validation accuracy: 0.469\n",
      "Countdown: 102 \n",
      "\n",
      "Epoch: 404:\n",
      "Training loss  : 0.25088, Training accuracy  : 0.913\n",
      "Validation loss: 4.913, Validation accuracy: 0.517\n",
      "Countdown: 101 \n",
      "\n",
      "Epoch: 405:\n",
      "Training loss  : 0.30931, Training accuracy  : 0.899\n",
      "Validation loss: 8.787, Validation accuracy: 0.358\n",
      "Countdown: 100 \n",
      "\n",
      "Epoch: 406:\n",
      "Training loss  : 0.31002, Training accuracy  : 0.899\n",
      "Validation loss: 5.824, Validation accuracy: 0.463\n",
      "Countdown: 99 \n",
      "\n",
      "Epoch: 407:\n",
      "Training loss  : 0.24215, Training accuracy  : 0.916\n",
      "Validation loss: 5.643, Validation accuracy: 0.489\n",
      "Countdown: 98 \n",
      "\n",
      "Epoch: 408:\n",
      "Training loss  : 0.26678, Training accuracy  : 0.906\n",
      "Validation loss: 6.460, Validation accuracy: 0.460\n",
      "Countdown: 97 \n",
      "\n",
      "Epoch: 409:\n",
      "Training loss  : 0.26178, Training accuracy  : 0.907\n",
      "Validation loss: 5.287, Validation accuracy: 0.495\n",
      "Countdown: 96 \n",
      "\n",
      "Epoch: 410:\n",
      "Training loss  : 0.25879, Training accuracy  : 0.907\n",
      "Validation loss: 5.417, Validation accuracy: 0.480\n",
      "Countdown: 95 \n",
      "\n",
      "Epoch: 411:\n",
      "Training loss  : 0.36888, Training accuracy  : 0.871\n",
      "Validation loss: 5.039, Validation accuracy: 0.465\n",
      "Countdown: 94 \n",
      "\n",
      "Epoch: 412:\n",
      "Training loss  : 0.38767, Training accuracy  : 0.872\n",
      "Validation loss: 4.992, Validation accuracy: 0.495\n",
      "Countdown: 93 \n",
      "\n",
      "Epoch: 413:\n",
      "Training loss  : 0.26035, Training accuracy  : 0.910\n",
      "Validation loss: 6.064, Validation accuracy: 0.453\n",
      "Countdown: 92 \n",
      "\n",
      "Epoch: 414:\n",
      "Training loss  : 0.29526, Training accuracy  : 0.903\n",
      "Validation loss: 5.053, Validation accuracy: 0.499\n",
      "Countdown: 91 \n",
      "\n",
      "Epoch: 415:\n",
      "Training loss  : 0.31252, Training accuracy  : 0.893\n",
      "Validation loss: 5.382, Validation accuracy: 0.476\n",
      "Countdown: 90 \n",
      "\n",
      "Epoch: 416:\n",
      "Training loss  : 0.26695, Training accuracy  : 0.906\n",
      "Validation loss: 5.213, Validation accuracy: 0.493\n",
      "Countdown: 89 \n",
      "\n",
      "Epoch: 417:\n",
      "Training loss  : 0.23806, Training accuracy  : 0.916\n",
      "Validation loss: 5.049, Validation accuracy: 0.510\n",
      "Countdown: 88 \n",
      "\n",
      "Epoch: 418:\n",
      "Training loss  : 0.28104, Training accuracy  : 0.903\n",
      "Validation loss: 5.796, Validation accuracy: 0.473\n",
      "Countdown: 87 \n",
      "\n",
      "Epoch: 419:\n",
      "Training loss  : 0.24763, Training accuracy  : 0.912\n",
      "Validation loss: 6.460, Validation accuracy: 0.470\n",
      "Countdown: 86 \n",
      "\n",
      "Epoch: 420:\n",
      "Training loss  : 0.24413, Training accuracy  : 0.914\n",
      "Validation loss: 6.417, Validation accuracy: 0.472\n",
      "Countdown: 85 \n",
      "\n",
      "Epoch: 421:\n",
      "Training loss  : 0.26252, Training accuracy  : 0.907\n",
      "Validation loss: 6.161, Validation accuracy: 0.457\n",
      "Countdown: 84 \n",
      "\n",
      "Epoch: 422:\n",
      "Training loss  : 0.22223, Training accuracy  : 0.920\n",
      "Validation loss: 5.288, Validation accuracy: 0.509\n",
      "Countdown: 83 \n",
      "\n",
      "Epoch: 423:\n",
      "Training loss  : 0.22597, Training accuracy  : 0.920\n",
      "Validation loss: 6.310, Validation accuracy: 0.453\n",
      "Countdown: 82 \n",
      "\n",
      "Epoch: 424:\n",
      "Training loss  : 0.26364, Training accuracy  : 0.906\n",
      "Validation loss: 6.959, Validation accuracy: 0.484\n",
      "Countdown: 81 \n",
      "\n",
      "Epoch: 425:\n",
      "Training loss  : 0.29863, Training accuracy  : 0.899\n",
      "Validation loss: 5.913, Validation accuracy: 0.485\n",
      "Countdown: 80 \n",
      "\n",
      "Epoch: 426:\n",
      "Training loss  : 0.25302, Training accuracy  : 0.912\n",
      "Validation loss: 6.010, Validation accuracy: 0.477\n",
      "Countdown: 79 \n",
      "\n",
      "Epoch: 427:\n",
      "Training loss  : 0.23674, Training accuracy  : 0.917\n",
      "Validation loss: 4.589, Validation accuracy: 0.516\n",
      "Countdown: 78 \n",
      "\n",
      "Epoch: 428:\n",
      "Training loss  : 0.26708, Training accuracy  : 0.903\n",
      "Validation loss: 5.254, Validation accuracy: 0.501\n",
      "Countdown: 77 \n",
      "\n",
      "Epoch: 429:\n",
      "Training loss  : 0.27778, Training accuracy  : 0.903\n",
      "Validation loss: 5.856, Validation accuracy: 0.416\n",
      "Countdown: 76 \n",
      "\n",
      "Epoch: 430:\n",
      "Training loss  : 0.31066, Training accuracy  : 0.893\n",
      "Validation loss: 5.959, Validation accuracy: 0.514\n",
      "Countdown: 75 \n",
      "\n",
      "Epoch: 431:\n",
      "Training loss  : 0.29300, Training accuracy  : 0.901\n",
      "Validation loss: 4.812, Validation accuracy: 0.529\n",
      "Countdown: 74 \n",
      "\n",
      "Epoch: 432:\n",
      "Training loss  : 0.28317, Training accuracy  : 0.901\n",
      "Validation loss: 5.498, Validation accuracy: 0.489\n",
      "Countdown: 73 \n",
      "\n",
      "Epoch: 433:\n",
      "Training loss  : 0.26885, Training accuracy  : 0.907\n",
      "Validation loss: 5.629, Validation accuracy: 0.475\n",
      "Countdown: 72 \n",
      "\n",
      "Epoch: 434:\n",
      "Training loss  : 0.24250, Training accuracy  : 0.913\n",
      "Validation loss: 6.730, Validation accuracy: 0.453\n",
      "Countdown: 71 \n",
      "\n",
      "Epoch: 435:\n",
      "Training loss  : 0.24090, Training accuracy  : 0.914\n",
      "Validation loss: 5.743, Validation accuracy: 0.494\n",
      "Countdown: 70 \n",
      "\n",
      "Epoch: 436:\n",
      "Training loss  : 0.23653, Training accuracy  : 0.915\n",
      "Validation loss: 5.656, Validation accuracy: 0.513\n",
      "Countdown: 69 \n",
      "\n",
      "Epoch: 437:\n",
      "Training loss  : 0.26839, Training accuracy  : 0.907\n",
      "Validation loss: 4.611, Validation accuracy: 0.497\n",
      "Countdown: 68 \n",
      "\n",
      "Epoch: 438:\n",
      "Training loss  : 0.26177, Training accuracy  : 0.905\n",
      "Validation loss: 5.682, Validation accuracy: 0.469\n",
      "Countdown: 67 \n",
      "\n",
      "Epoch: 439:\n",
      "Training loss  : 0.25524, Training accuracy  : 0.908\n",
      "Validation loss: 5.495, Validation accuracy: 0.460\n",
      "Countdown: 66 \n",
      "\n",
      "Epoch: 440:\n",
      "Training loss  : 0.26235, Training accuracy  : 0.907\n",
      "Validation loss: 6.886, Validation accuracy: 0.400\n",
      "Countdown: 65 \n",
      "\n",
      "Epoch: 441:\n",
      "Training loss  : 0.26078, Training accuracy  : 0.911\n",
      "Validation loss: 5.257, Validation accuracy: 0.485\n",
      "Countdown: 64 \n",
      "\n",
      "Epoch: 442:\n",
      "Training loss  : 0.26215, Training accuracy  : 0.905\n",
      "Validation loss: 5.439, Validation accuracy: 0.494\n",
      "Countdown: 63 \n",
      "\n",
      "Epoch: 443:\n",
      "Training loss  : 0.25558, Training accuracy  : 0.910\n",
      "Validation loss: 6.074, Validation accuracy: 0.432\n",
      "Countdown: 62 \n",
      "\n",
      "Epoch: 444:\n",
      "Training loss  : 0.26201, Training accuracy  : 0.909\n",
      "Validation loss: 5.488, Validation accuracy: 0.510\n",
      "Countdown: 61 \n",
      "\n",
      "Epoch: 445:\n",
      "Training loss  : 0.29655, Training accuracy  : 0.895\n",
      "Validation loss: 6.303, Validation accuracy: 0.395\n",
      "Countdown: 60 \n",
      "\n",
      "Epoch: 446:\n",
      "Training loss  : 0.26865, Training accuracy  : 0.905\n",
      "Validation loss: 5.856, Validation accuracy: 0.461\n",
      "Countdown: 59 \n",
      "\n",
      "Epoch: 447:\n",
      "Training loss  : 0.28768, Training accuracy  : 0.899\n",
      "Validation loss: 5.142, Validation accuracy: 0.510\n",
      "Countdown: 58 \n",
      "\n",
      "Epoch: 448:\n",
      "Training loss  : 0.27981, Training accuracy  : 0.907\n",
      "Validation loss: 5.522, Validation accuracy: 0.463\n",
      "Countdown: 57 \n",
      "\n",
      "Epoch: 449:\n",
      "Training loss  : 0.27103, Training accuracy  : 0.905\n",
      "Validation loss: 4.769, Validation accuracy: 0.520\n",
      "Countdown: 56 \n",
      "\n",
      "Epoch: 450:\n",
      "Training loss  : 0.26792, Training accuracy  : 0.904\n",
      "Validation loss: 5.654, Validation accuracy: 0.511\n",
      "Countdown: 55 \n",
      "\n",
      "Epoch: 451:\n",
      "Training loss  : 0.31215, Training accuracy  : 0.897\n",
      "Validation loss: 4.196, Validation accuracy: 0.472\n",
      "Countdown: 54 \n",
      "\n",
      "Epoch: 452:\n",
      "Training loss  : 0.33587, Training accuracy  : 0.884\n",
      "Validation loss: 6.172, Validation accuracy: 0.468\n",
      "Countdown: 53 \n",
      "\n",
      "Epoch: 453:\n",
      "Training loss  : 0.25385, Training accuracy  : 0.910\n",
      "Validation loss: 6.332, Validation accuracy: 0.464\n",
      "Countdown: 52 \n",
      "\n",
      "Epoch: 454:\n",
      "Training loss  : 0.21592, Training accuracy  : 0.925\n",
      "Validation loss: 5.626, Validation accuracy: 0.497\n",
      "Countdown: 51 \n",
      "\n",
      "Epoch: 455:\n",
      "Training loss  : 0.24942, Training accuracy  : 0.911\n",
      "Validation loss: 5.719, Validation accuracy: 0.484\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 456:\n",
      "Training loss  : 0.26171, Training accuracy  : 0.910\n",
      "Validation loss: 5.747, Validation accuracy: 0.466\n",
      "Countdown: 49 \n",
      "\n",
      "Epoch: 457:\n",
      "Training loss  : 0.30979, Training accuracy  : 0.891\n",
      "Validation loss: 6.824, Validation accuracy: 0.481\n",
      "Countdown: 48 \n",
      "\n",
      "Epoch: 458:\n",
      "Training loss  : 0.31159, Training accuracy  : 0.891\n",
      "Validation loss: 6.003, Validation accuracy: 0.502\n",
      "Countdown: 47 \n",
      "\n",
      "Epoch: 459:\n",
      "Training loss  : 0.30266, Training accuracy  : 0.896\n",
      "Validation loss: 6.048, Validation accuracy: 0.444\n",
      "Countdown: 46 \n",
      "\n",
      "Epoch: 460:\n",
      "Training loss  : 0.26752, Training accuracy  : 0.904\n",
      "Validation loss: 5.975, Validation accuracy: 0.499\n",
      "Countdown: 45 \n",
      "\n",
      "Epoch: 461:\n",
      "Training loss  : 0.23906, Training accuracy  : 0.916\n",
      "Validation loss: 6.271, Validation accuracy: 0.475\n",
      "Countdown: 44 \n",
      "\n",
      "Epoch: 462:\n",
      "Training loss  : 0.28095, Training accuracy  : 0.903\n",
      "Validation loss: 7.110, Validation accuracy: 0.475\n",
      "Countdown: 43 \n",
      "\n",
      "Epoch: 463:\n",
      "Training loss  : 0.27433, Training accuracy  : 0.907\n",
      "Validation loss: 7.493, Validation accuracy: 0.459\n",
      "Countdown: 42 \n",
      "\n",
      "Epoch: 464:\n",
      "Training loss  : 0.24987, Training accuracy  : 0.912\n",
      "Validation loss: 6.531, Validation accuracy: 0.489\n",
      "Countdown: 41 \n",
      "\n",
      "Epoch: 465:\n",
      "Training loss  : 0.25104, Training accuracy  : 0.912\n",
      "Validation loss: 6.458, Validation accuracy: 0.465\n",
      "Countdown: 40 \n",
      "\n",
      "Epoch: 466:\n",
      "Training loss  : 0.24234, Training accuracy  : 0.912\n",
      "Validation loss: 6.199, Validation accuracy: 0.500\n",
      "Countdown: 39 \n",
      "\n",
      "Epoch: 467:\n",
      "Training loss  : 0.33722, Training accuracy  : 0.883\n",
      "Validation loss: 4.661, Validation accuracy: 0.472\n",
      "Countdown: 38 \n",
      "\n",
      "Epoch: 468:\n",
      "Training loss  : 0.30790, Training accuracy  : 0.900\n",
      "Validation loss: 5.048, Validation accuracy: 0.438\n",
      "Countdown: 37 \n",
      "\n",
      "Epoch: 469:\n",
      "Training loss  : 0.26711, Training accuracy  : 0.909\n",
      "Validation loss: 5.677, Validation accuracy: 0.496\n",
      "Countdown: 36 \n",
      "\n",
      "Epoch: 470:\n",
      "Training loss  : 0.24642, Training accuracy  : 0.911\n",
      "Validation loss: 5.151, Validation accuracy: 0.526\n",
      "Countdown: 35 \n",
      "\n",
      "Epoch: 471:\n",
      "Training loss  : 0.31143, Training accuracy  : 0.894\n",
      "Validation loss: 4.916, Validation accuracy: 0.502\n",
      "Countdown: 34 \n",
      "\n",
      "Epoch: 472:\n",
      "Training loss  : 0.26971, Training accuracy  : 0.908\n",
      "Validation loss: 5.830, Validation accuracy: 0.466\n",
      "Countdown: 33 \n",
      "\n",
      "Epoch: 473:\n",
      "Training loss  : 0.26815, Training accuracy  : 0.910\n",
      "Validation loss: 6.449, Validation accuracy: 0.496\n",
      "Countdown: 32 \n",
      "\n",
      "Epoch: 474:\n",
      "Training loss  : 0.23551, Training accuracy  : 0.919\n",
      "Validation loss: 7.363, Validation accuracy: 0.416\n",
      "Countdown: 31 \n",
      "\n",
      "Epoch: 475:\n",
      "Training loss  : 0.22518, Training accuracy  : 0.920\n",
      "Validation loss: 5.722, Validation accuracy: 0.506\n",
      "Countdown: 30 \n",
      "\n",
      "Epoch: 476:\n",
      "Training loss  : 0.26545, Training accuracy  : 0.910\n",
      "Validation loss: 7.701, Validation accuracy: 0.449\n",
      "Countdown: 29 \n",
      "\n",
      "Epoch: 477:\n",
      "Training loss  : 0.30352, Training accuracy  : 0.896\n",
      "Validation loss: 7.623, Validation accuracy: 0.483\n",
      "Countdown: 28 \n",
      "\n",
      "Epoch: 478:\n",
      "Training loss  : 0.25569, Training accuracy  : 0.913\n",
      "Validation loss: 7.273, Validation accuracy: 0.430\n",
      "Countdown: 27 \n",
      "\n",
      "Epoch: 479:\n",
      "Training loss  : 0.24877, Training accuracy  : 0.914\n",
      "Validation loss: 5.688, Validation accuracy: 0.518\n",
      "Countdown: 26 \n",
      "\n",
      "Epoch: 480:\n",
      "Training loss  : 0.22561, Training accuracy  : 0.921\n",
      "Validation loss: 6.673, Validation accuracy: 0.466\n",
      "Countdown: 25 \n",
      "\n",
      "Epoch: 481:\n",
      "Training loss  : 0.22772, Training accuracy  : 0.922\n",
      "Validation loss: 7.474, Validation accuracy: 0.418\n",
      "Countdown: 24 \n",
      "\n",
      "Epoch: 482:\n",
      "Training loss  : 0.24991, Training accuracy  : 0.909\n",
      "Validation loss: 5.947, Validation accuracy: 0.461\n",
      "Countdown: 23 \n",
      "\n",
      "Epoch: 483:\n",
      "Training loss  : 0.23747, Training accuracy  : 0.916\n",
      "Validation loss: 5.883, Validation accuracy: 0.462\n",
      "Countdown: 22 \n",
      "\n",
      "Epoch: 484:\n",
      "Training loss  : 0.24191, Training accuracy  : 0.912\n",
      "Validation loss: 6.021, Validation accuracy: 0.511\n",
      "Countdown: 21 \n",
      "\n",
      "Epoch: 485:\n",
      "Training loss  : 0.27658, Training accuracy  : 0.901\n",
      "Validation loss: 5.793, Validation accuracy: 0.520\n",
      "Countdown: 20 \n",
      "\n",
      "Epoch: 486:\n",
      "Training loss  : 0.29606, Training accuracy  : 0.902\n",
      "Validation loss: 6.672, Validation accuracy: 0.433\n",
      "Countdown: 19 \n",
      "\n",
      "Epoch: 487:\n",
      "Training loss  : 0.29617, Training accuracy  : 0.898\n",
      "Validation loss: 6.522, Validation accuracy: 0.483\n",
      "Countdown: 18 \n",
      "\n",
      "Epoch: 488:\n",
      "Training loss  : 0.26417, Training accuracy  : 0.907\n",
      "Validation loss: 6.598, Validation accuracy: 0.432\n",
      "Countdown: 17 \n",
      "\n",
      "Epoch: 489:\n",
      "Training loss  : 0.24684, Training accuracy  : 0.911\n",
      "Validation loss: 6.772, Validation accuracy: 0.430\n",
      "Countdown: 16 \n",
      "\n",
      "Epoch: 490:\n",
      "Training loss  : 0.22339, Training accuracy  : 0.921\n",
      "Validation loss: 7.168, Validation accuracy: 0.386\n",
      "Countdown: 15 \n",
      "\n",
      "Epoch: 491:\n",
      "Training loss  : 0.23193, Training accuracy  : 0.917\n",
      "Validation loss: 6.495, Validation accuracy: 0.472\n",
      "Countdown: 14 \n",
      "\n",
      "Epoch: 492:\n",
      "Training loss  : 0.27716, Training accuracy  : 0.900\n",
      "Validation loss: 5.290, Validation accuracy: 0.432\n",
      "Countdown: 13 \n",
      "\n",
      "Epoch: 493:\n",
      "Training loss  : 0.41917, Training accuracy  : 0.868\n",
      "Validation loss: 5.233, Validation accuracy: 0.419\n",
      "Countdown: 12 \n",
      "\n",
      "Epoch: 494:\n",
      "Training loss  : 0.30626, Training accuracy  : 0.897\n",
      "Validation loss: 5.292, Validation accuracy: 0.453\n",
      "Countdown: 11 \n",
      "\n",
      "Epoch: 495:\n",
      "Training loss  : 0.25182, Training accuracy  : 0.911\n",
      "Validation loss: 6.277, Validation accuracy: 0.478\n",
      "Countdown: 10 \n",
      "\n",
      "Epoch: 496:\n",
      "Training loss  : 0.26884, Training accuracy  : 0.906\n",
      "Validation loss: 6.472, Validation accuracy: 0.498\n",
      "Countdown: 9 \n",
      "\n",
      "Epoch: 497:\n",
      "Training loss  : 0.24843, Training accuracy  : 0.916\n",
      "Validation loss: 5.009, Validation accuracy: 0.497\n",
      "Countdown: 8 \n",
      "\n",
      "Epoch: 498:\n",
      "Training loss  : 0.26502, Training accuracy  : 0.907\n",
      "Validation loss: 5.928, Validation accuracy: 0.469\n",
      "Countdown: 7 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Patience is the number of epochs that we have to wait for no\n",
    "# loss decrease in the validation set to apply early stopping\n",
    "# instead of waitng till the end of epochs (999)\n",
    "lr = 0.01\n",
    "patience = 500 \n",
    "epochs = 999\n",
    "\n",
    "# Instantiate model\n",
    "nn1 = MLP1().to(device)\n",
    "print(nn1)\n",
    "# Set loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(nn1.parameters(), lr=lr)\n",
    "# training\n",
    "_, _, _ = trainNN(model=nn1, patience=patience, best_model_name=\"MLP1\",\n",
    "                epochs=epochs, trainloader=trainloader, valloader=valloader, \n",
    "                device=device, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP2(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=128, out_features=16, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: 1:\n",
      "Training loss  : 2.74194, Training accuracy  : 0.070\n",
      "Validation loss: 2.737, Validation accuracy: 0.068\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 2:\n",
      "Training loss  : 2.72748, Training accuracy  : 0.206\n",
      "Validation loss: 2.709, Validation accuracy: 0.260\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 3:\n",
      "Training loss  : 2.64833, Training accuracy  : 0.236\n",
      "Validation loss: 2.489, Validation accuracy: 0.256\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 4:\n",
      "Training loss  : 2.32600, Training accuracy  : 0.303\n",
      "Validation loss: 2.153, Validation accuracy: 0.388\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 5:\n",
      "Training loss  : 2.05530, Training accuracy  : 0.359\n",
      "Validation loss: 1.929, Validation accuracy: 0.387\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 6:\n",
      "Training loss  : 1.83892, Training accuracy  : 0.360\n",
      "Validation loss: 1.780, Validation accuracy: 0.400\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 7:\n",
      "Training loss  : 1.71155, Training accuracy  : 0.380\n",
      "Validation loss: 1.709, Validation accuracy: 0.427\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 8:\n",
      "Training loss  : 1.63826, Training accuracy  : 0.421\n",
      "Validation loss: 1.672, Validation accuracy: 0.431\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 9:\n",
      "Training loss  : 1.59482, Training accuracy  : 0.447\n",
      "Validation loss: 1.652, Validation accuracy: 0.436\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 10:\n",
      "Training loss  : 1.56563, Training accuracy  : 0.451\n",
      "Validation loss: 1.647, Validation accuracy: 0.438\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 11:\n",
      "Training loss  : 1.54252, Training accuracy  : 0.455\n",
      "Validation loss: 1.644, Validation accuracy: 0.440\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 12:\n",
      "Training loss  : 1.52475, Training accuracy  : 0.457\n",
      "Validation loss: 1.644, Validation accuracy: 0.440\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 13:\n",
      "Training loss  : 1.50970, Training accuracy  : 0.457\n",
      "Validation loss: 1.645, Validation accuracy: 0.441\n",
      "Countdown: 50 \n",
      "\n",
      "Epoch: 14:\n",
      "Training loss  : 1.49631, Training accuracy  : 0.458\n",
      "Validation loss: 1.649, Validation accuracy: 0.443\n",
      "Countdown: 49 \n",
      "\n",
      "Epoch: 15:\n",
      "Training loss  : 1.48481, Training accuracy  : 0.460\n",
      "Validation loss: 1.653, Validation accuracy: 0.443\n",
      "Countdown: 48 \n",
      "\n",
      "Epoch: 16:\n",
      "Training loss  : 1.47446, Training accuracy  : 0.463\n",
      "Validation loss: 1.657, Validation accuracy: 0.445\n",
      "Countdown: 47 \n",
      "\n",
      "Epoch: 17:\n",
      "Training loss  : 1.46519, Training accuracy  : 0.464\n",
      "Validation loss: 1.664, Validation accuracy: 0.444\n",
      "Countdown: 46 \n",
      "\n",
      "Epoch: 18:\n",
      "Training loss  : 1.45653, Training accuracy  : 0.466\n",
      "Validation loss: 1.671, Validation accuracy: 0.444\n",
      "Countdown: 45 \n",
      "\n",
      "Epoch: 19:\n",
      "Training loss  : 1.44843, Training accuracy  : 0.467\n",
      "Validation loss: 1.681, Validation accuracy: 0.444\n",
      "Countdown: 44 \n",
      "\n",
      "Epoch: 20:\n",
      "Training loss  : 1.44095, Training accuracy  : 0.468\n",
      "Validation loss: 1.686, Validation accuracy: 0.444\n",
      "Countdown: 43 \n",
      "\n",
      "Epoch: 21:\n",
      "Training loss  : 1.43399, Training accuracy  : 0.470\n",
      "Validation loss: 1.696, Validation accuracy: 0.444\n",
      "Countdown: 42 \n",
      "\n",
      "Epoch: 22:\n",
      "Training loss  : 1.42757, Training accuracy  : 0.471\n",
      "Validation loss: 1.703, Validation accuracy: 0.443\n",
      "Countdown: 41 \n",
      "\n",
      "Epoch: 23:\n",
      "Training loss  : 1.42147, Training accuracy  : 0.472\n",
      "Validation loss: 1.714, Validation accuracy: 0.443\n",
      "Countdown: 40 \n",
      "\n",
      "Epoch: 24:\n",
      "Training loss  : 1.41589, Training accuracy  : 0.475\n",
      "Validation loss: 1.723, Validation accuracy: 0.443\n",
      "Countdown: 39 \n",
      "\n",
      "Epoch: 25:\n",
      "Training loss  : 1.41064, Training accuracy  : 0.475\n",
      "Validation loss: 1.731, Validation accuracy: 0.443\n",
      "Countdown: 38 \n",
      "\n",
      "Epoch: 26:\n",
      "Training loss  : 1.40573, Training accuracy  : 0.476\n",
      "Validation loss: 1.740, Validation accuracy: 0.443\n",
      "Countdown: 37 \n",
      "\n",
      "Epoch: 27:\n",
      "Training loss  : 1.40115, Training accuracy  : 0.476\n",
      "Validation loss: 1.750, Validation accuracy: 0.443\n",
      "Countdown: 36 \n",
      "\n",
      "Epoch: 28:\n",
      "Training loss  : 1.39686, Training accuracy  : 0.478\n",
      "Validation loss: 1.759, Validation accuracy: 0.443\n",
      "Countdown: 35 \n",
      "\n",
      "Epoch: 29:\n",
      "Training loss  : 1.39268, Training accuracy  : 0.479\n",
      "Validation loss: 1.766, Validation accuracy: 0.443\n",
      "Countdown: 34 \n",
      "\n",
      "Epoch: 30:\n",
      "Training loss  : 1.38858, Training accuracy  : 0.481\n",
      "Validation loss: 1.776, Validation accuracy: 0.444\n",
      "Countdown: 33 \n",
      "\n",
      "Epoch: 31:\n",
      "Training loss  : 1.38455, Training accuracy  : 0.482\n",
      "Validation loss: 1.787, Validation accuracy: 0.443\n",
      "Countdown: 32 \n",
      "\n",
      "Epoch: 32:\n",
      "Training loss  : 1.38084, Training accuracy  : 0.483\n",
      "Validation loss: 1.798, Validation accuracy: 0.443\n",
      "Countdown: 31 \n",
      "\n",
      "Epoch: 33:\n",
      "Training loss  : 1.37732, Training accuracy  : 0.484\n",
      "Validation loss: 1.807, Validation accuracy: 0.443\n",
      "Countdown: 30 \n",
      "\n",
      "Epoch: 34:\n",
      "Training loss  : 1.37390, Training accuracy  : 0.485\n",
      "Validation loss: 1.817, Validation accuracy: 0.442\n",
      "Countdown: 29 \n",
      "\n",
      "Epoch: 35:\n",
      "Training loss  : 1.37069, Training accuracy  : 0.485\n",
      "Validation loss: 1.825, Validation accuracy: 0.441\n",
      "Countdown: 28 \n",
      "\n",
      "Epoch: 36:\n",
      "Training loss  : 1.36761, Training accuracy  : 0.485\n",
      "Validation loss: 1.835, Validation accuracy: 0.441\n",
      "Countdown: 27 \n",
      "\n",
      "Epoch: 37:\n",
      "Training loss  : 1.36479, Training accuracy  : 0.487\n",
      "Validation loss: 1.843, Validation accuracy: 0.441\n",
      "Countdown: 26 \n",
      "\n",
      "Epoch: 38:\n",
      "Training loss  : 1.36204, Training accuracy  : 0.487\n",
      "Validation loss: 1.851, Validation accuracy: 0.441\n",
      "Countdown: 25 \n",
      "\n",
      "Epoch: 39:\n",
      "Training loss  : 1.35935, Training accuracy  : 0.489\n",
      "Validation loss: 1.862, Validation accuracy: 0.441\n",
      "Countdown: 24 \n",
      "\n",
      "Epoch: 40:\n",
      "Training loss  : 1.35681, Training accuracy  : 0.489\n",
      "Validation loss: 1.872, Validation accuracy: 0.441\n",
      "Countdown: 23 \n",
      "\n",
      "Epoch: 41:\n",
      "Training loss  : 1.35426, Training accuracy  : 0.489\n",
      "Validation loss: 1.885, Validation accuracy: 0.441\n",
      "Countdown: 22 \n",
      "\n",
      "Epoch: 42:\n",
      "Training loss  : 1.35179, Training accuracy  : 0.490\n",
      "Validation loss: 1.895, Validation accuracy: 0.441\n",
      "Countdown: 21 \n",
      "\n",
      "Epoch: 43:\n",
      "Training loss  : 1.34941, Training accuracy  : 0.491\n",
      "Validation loss: 1.904, Validation accuracy: 0.441\n",
      "Countdown: 20 \n",
      "\n",
      "Epoch: 44:\n",
      "Training loss  : 1.34698, Training accuracy  : 0.491\n",
      "Validation loss: 1.913, Validation accuracy: 0.440\n",
      "Countdown: 19 \n",
      "\n",
      "Epoch: 45:\n",
      "Training loss  : 1.34466, Training accuracy  : 0.492\n",
      "Validation loss: 1.923, Validation accuracy: 0.440\n",
      "Countdown: 18 \n",
      "\n",
      "Epoch: 46:\n",
      "Training loss  : 1.34240, Training accuracy  : 0.494\n",
      "Validation loss: 1.932, Validation accuracy: 0.440\n",
      "Countdown: 17 \n",
      "\n",
      "Epoch: 47:\n",
      "Training loss  : 1.34021, Training accuracy  : 0.494\n",
      "Validation loss: 1.942, Validation accuracy: 0.440\n",
      "Countdown: 16 \n",
      "\n",
      "Epoch: 48:\n",
      "Training loss  : 1.33815, Training accuracy  : 0.494\n",
      "Validation loss: 1.951, Validation accuracy: 0.440\n",
      "Countdown: 15 \n",
      "\n",
      "Epoch: 49:\n",
      "Training loss  : 1.33623, Training accuracy  : 0.494\n",
      "Validation loss: 1.962, Validation accuracy: 0.440\n",
      "Countdown: 14 \n",
      "\n",
      "Epoch: 50:\n",
      "Training loss  : 1.33432, Training accuracy  : 0.494\n",
      "Validation loss: 1.969, Validation accuracy: 0.440\n",
      "Countdown: 13 \n",
      "\n",
      "Epoch: 51:\n",
      "Training loss  : 1.33241, Training accuracy  : 0.494\n",
      "Validation loss: 1.977, Validation accuracy: 0.440\n",
      "Countdown: 12 \n",
      "\n",
      "Epoch: 52:\n",
      "Training loss  : 1.33059, Training accuracy  : 0.495\n",
      "Validation loss: 1.988, Validation accuracy: 0.440\n",
      "Countdown: 11 \n",
      "\n",
      "Epoch: 53:\n",
      "Training loss  : 1.32878, Training accuracy  : 0.495\n",
      "Validation loss: 1.995, Validation accuracy: 0.440\n",
      "Countdown: 10 \n",
      "\n",
      "Epoch: 54:\n",
      "Training loss  : 1.32699, Training accuracy  : 0.495\n",
      "Validation loss: 2.004, Validation accuracy: 0.440\n",
      "Countdown: 9 \n",
      "\n",
      "Epoch: 55:\n",
      "Training loss  : 1.32530, Training accuracy  : 0.496\n",
      "Validation loss: 2.014, Validation accuracy: 0.440\n",
      "Countdown: 8 \n",
      "\n",
      "Epoch: 56:\n",
      "Training loss  : 1.32359, Training accuracy  : 0.496\n",
      "Validation loss: 2.023, Validation accuracy: 0.440\n",
      "Countdown: 7 \n",
      "\n",
      "Epoch: 57:\n",
      "Training loss  : 1.32195, Training accuracy  : 0.497\n",
      "Validation loss: 2.027, Validation accuracy: 0.440\n",
      "Countdown: 6 \n",
      "\n",
      "Epoch: 58:\n",
      "Training loss  : 1.32023, Training accuracy  : 0.498\n",
      "Validation loss: 2.042, Validation accuracy: 0.440\n",
      "Countdown: 5 \n",
      "\n",
      "Epoch: 59:\n",
      "Training loss  : 1.31905, Training accuracy  : 0.498\n",
      "Validation loss: 2.051, Validation accuracy: 0.440\n",
      "Countdown: 4 \n",
      "\n",
      "Epoch: 60:\n",
      "Training loss  : 1.31747, Training accuracy  : 0.498\n",
      "Validation loss: 2.060, Validation accuracy: 0.440\n",
      "Countdown: 3 \n",
      "\n",
      "Epoch: 61:\n",
      "Training loss  : 1.31609, Training accuracy  : 0.498\n",
      "Validation loss: 2.070, Validation accuracy: 0.439\n",
      "Countdown: 2 \n",
      "\n",
      "Epoch: 62:\n",
      "Training loss  : 1.31467, Training accuracy  : 0.498\n",
      "Validation loss: 2.079, Validation accuracy: 0.439\n",
      "Countdown: 1 \n",
      "\n",
      "Finished Training!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-5\n",
    "patience = 50 # initialise here\n",
    "epochs = 999\n",
    "\n",
    "# Instantiate model\n",
    "nn2 = MLP2(input_dim=X_train.shape[1], output_dim=16).to(device)\n",
    "print(nn2)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(nn2.parameters(), lr=lr)\n",
    "\n",
    "# training\n",
    "epoch_loss_train, epoch_loss_val, epoch = trainNN(model=nn2, patience=patience, best_model_name=\"MLP2\",\n",
    "                                           epochs=epochs, trainloader=trainloader, valloader=valloader, \n",
    "                                           device=device, optimizer=optimizer, criterion=criterion)\n",
    "\n",
    "# Plot Train / Validation Loss\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
    "plt.figure()\n",
    "plt.title(\"Relative Loss\")\n",
    "plt.plot(list(range(1,epoch+1)), epoch_loss_train, label='Training set')\n",
    "plt.plot(list(range(1,epoch+1)), epoch_loss_val,  label='Validation set')\n",
    "plt.grid()\n",
    "plt.ylim(0, 3)\n",
    "plt.legend(fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Load Best model \n",
    "# =============================================================================\n",
    "# Select model file name between specific list of prerun models (Models folder)\n",
    "stored_models = [\"simple\", \"Bi\", \"BiDr\", \"BiDrRe\", \"BiDrRe_packed\"]\n",
    "best_model_name = stored_models[0]\n",
    "\n",
    "# I load the appropriate model\n",
    "model = torch.load(os.path.join(os.getcwd(),\n",
    "                   \"models\"+os.path.sep+best_model_name+\".pt\"))\n",
    "# To set dropout and batch normalization layers to evaluation mode \n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Best Model on validation set\n",
    "# =============================================================================\n",
    "y_pred_val = []\n",
    "y_val = [] # I reconstruct it in the right order\n",
    "batch_loss = []\n",
    "batch_acc = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(valloader):\n",
    "        inputs_val = data['bands'].to(device) \n",
    "        labels_val = data['labels'].to(device)\n",
    "        batch_pred = model(inputs_val)\n",
    "        loss = criterion(batch_pred, labels_val)\n",
    "        batch_loss.append(loss.item())\n",
    "        batch_pred = [np.argmax(batch_pred[i].\n",
    "                            to(torch.device('cpu')).\n",
    "                            detach().numpy()) for i in range(len(batch_pred))]\n",
    "        y_pred_val.append(batch_pred)\n",
    "        y_val.append(data['labels'])\n",
    "        batch_acc.append(metrics.\n",
    "                         accuracy_score(labels_val.\n",
    "                                        to(torch.device('cpu')).\n",
    "                                        detach().numpy(), batch_pred))\n",
    "    print(\"Validation loss: {:1.3f}, Validation Acc: {:1.3f} \\n\".\n",
    "          format(np.mean(batch_loss), np.mean(batch_acc)))\n",
    "# Predicted labels to numpy array\n",
    "y_pred_val = np.concatenate([y_pred_val[i] \n",
    "                             for i in range(len(y_pred_val))]).reshape(-1)\n",
    "y_val = np.concatenate([y_val[i] for i in range(len(y_val))]).reshape(-1)\n",
    "# =============================================================================\n",
    "# Confusion Matrix Validation Set\n",
    "# =============================================================================\n",
    "# Validation\n",
    "labels = list(set(y_val))\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "cnf_mat = confusion_matrix(y_val, y_pred_val, \n",
    "                           labels=list(range(num_classes)))\n",
    "print(\"\\n\")\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_mat, classes=labels, \n",
    "                      title='Confusion matrix of validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Evaluation with various classification metrics (classification report)\n",
    "###############################################################################\n",
    "from confusion_matrix import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=69, stratify=y)\n",
    "\n",
    "models = {'kNN': KNeighborsClassifier(n_neighbors=3),\n",
    "          'NB': GaussianNB(),\n",
    "          'MLP1':\n",
    "          'MLP2':  }\n",
    "# Create scores dictionary for each algorithm\n",
    "scores=[]\n",
    "mdl=[]\n",
    "results=[]\n",
    "for model in models.keys():\n",
    "    clf = models[model]\n",
    "    clf.fit(X_train,  y_train)\n",
    "    mdl.append(model)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results.append((clf.score(X_test, y_test), y_pred))\n",
    "    print (model, \"\\n\")\n",
    "    print(metrics.classification_report(y_test, y_pred, digits=5))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=[0,1], title=model, cmap=plt.cm.Greens)\n",
    "    print(\"True Positives: {}, False Positives: {}, True Negatives:, False Negatives: {} \\n\\n\".format(cm[0,0], cm[0,1], cm[1,1], cm[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Evaluation with various classification metrics (classification report)\n",
    "###############################################################################\n",
    "from confusion_matrix import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "N=1000\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=69, stratify=y)\n",
    "X_train, X_test, y_train, y_test = X_train[:N,:], X_test[:N,:], y_train[:N], y_test[:N]\n",
    "\n",
    "models = {'kNN': KNeighborsClassifier(n_neighbors=3),\n",
    "          'NB': GaussianNB(),\n",
    "          'Perceptron': Perceptron(penalty='l1')}\n",
    "# Create scores dictionary for each algorithm\n",
    "scores=[]\n",
    "mdl=[]\n",
    "results=[]\n",
    "for model in models.keys():\n",
    "    clf = models[model]\n",
    "    clf.fit(X_train,  y_train)\n",
    "    mdl.append(model)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results.append((clf.score(X_test, y_test), y_pred))\n",
    "    print (model, \"\\n\")\n",
    "    print(metrics.classification_report(y_test, y_pred, digits=5))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=[0,1], title=model, cmap=plt.cm.Greens)\n",
    "    print(\"True Positives: {}, False Positives: {}, True Negatives:, False Negatives: {} \\n\\n\".format(cm[0,0], cm[0,1], cm[1,1], cm[1,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
